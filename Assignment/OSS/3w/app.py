import streamlit as st
import pandas as pd
from io import StringIO
import time
import json
import logging
from datetime import datetime
import os
import streamlit.components.v1 as components

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "openai_api_key" not in st.session_state:
    st.session_state.openai_api_key = ""
logger = logging.getLogger("log-analyzer-app")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ë¡œê·¸ ë¶„ì„ê¸°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
    <style>
    /* CSS ìŠ¤íƒ€ì¼ ì •ì˜ */
    </style>
""", unsafe_allow_html=True)

# --- ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì—ì„œ API í‚¤ ë¡œë“œ/ì €ì¥ìš© JS ì‚½ì… ---
components.html(
    '''<script>
      const key = localStorage.getItem('OPENAI_API_KEY');
      if (key) window.parent.postMessage({ type:'loadKey', key }, '*');
      window.addEventListener('message', e => {
        if (e.data?.type==='saveKey') localStorage.setItem('OPENAI_API_KEY', e.data.key);
      });
    </script>''',
    height=0,
)
# ë¡œë“œëœ í‚¤ë¥¼ ì„¸ì…˜ì— ë°˜ì˜
msg = st.query_params.get('message')
if msg:
    try:
        data = json.loads(msg[0])
        if data.get('type')=='loadKey':
            st.session_state.openai_api_key = data['key']
    except:
        pass

from log_processor import process_log, normalize_logs, process_text_logs
from gpt_analyzer import GPTAnalyzer
from visualization.charts import plot_log_frequency, plot_error_distribution
from utils import format_timestamp, export_results
from config import SIDEBAR_STYLE, THEME_COLORS, get_api_key

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'logs' not in st.session_state:
    st.session_state.logs = None
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'is_analyzing' not in st.session_state:
    st.session_state.is_analyzing = False
if 'last_analyzed' not in st.session_state:
    st.session_state.last_analyzed = None
if 'response_language' not in st.session_state:
    st.session_state.response_language = "í•œêµ­ì–´"
if 'detailed_analysis' not in st.session_state:
    st.session_state.detailed_analysis = None
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []
if 'detailed_analysis_history' not in st.session_state:
    st.session_state.detailed_analysis_history = []
if 'previous_source_option' not in st.session_state:
    st.session_state.previous_source_option = None
if 'clear_on_source_change' not in st.session_state:
    st.session_state.clear_on_source_change = True

# ëª¨ë¸ ì˜µì…˜ ë°˜ì˜: ë¶„ì„ ì‹œì ì— GPTAnalyzer ìƒì„±

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.title("ğŸ” AI ë¡œê·¸ ë¶„ì„ê¸°")
    st.divider()

    st.subheader("ë¡œê·¸ ì†ŒìŠ¤ ì„ íƒ")
    source_option = st.radio(
        "ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ["íŒŒì¼ ì—…ë¡œë“œ", "í…ìŠ¤íŠ¸ ì…ë ¥", "ìƒ˜í”Œ ë°ì´í„°"]
    )
    # ìƒì„¸ ë¶„ì„ ì´ë ¥ ìë™ ì´ˆê¸°í™” ì˜µì…˜
    st.checkbox(
        "ìƒˆ ë¡œê·¸ ì†ŒìŠ¤ ì„ íƒ ì‹œ ìƒì„¸ ë¶„ì„ ì´ˆê¸°í™”",
        value=st.session_state.clear_on_source_change,
        key="clear_on_source_change"
    )
    # ì†ŒìŠ¤ ë³€ê²½ ê°ì§€ í›„ ì´ë ¥ ì´ˆê¸°í™”
    if st.session_state.previous_source_option is not None and source_option != st.session_state.previous_source_option and st.session_state.clear_on_source_change:
        st.session_state.detailed_analysis_history = []
    st.session_state.previous_source_option = source_option

    st.divider()
    st.subheader("ë¶„ì„ ì„¤ì •")
    temperature = st.slider("GPT ì°½ì˜ì„± ìˆ˜ì¤€", 0.0, 1.0, 0.7, 0.1)
    model_option = st.selectbox(
        "GPT ëª¨ë¸ ì„ íƒ",
        ["gpt-3.5-turbo", "gpt-4"]
    )

    st.subheader("ì‘ë‹µ ì–¸ì–´")
    language_option = st.selectbox("ì‘ë‹µ ì–¸ì–´", ["í•œêµ­ì–´", "English"], index=0, key="response_language")

    st.divider()
    st.subheader("ì‹œê°í™” ì„¤ì •")
    chart_type = st.selectbox(
        "ì°¨íŠ¸ ìœ í˜•",
        ["ë§‰ëŒ€ ì°¨íŠ¸", "ë¼ì¸ ì°¨íŠ¸", "íŒŒì´ ì°¨íŠ¸", "íˆíŠ¸ë§µ"]
    )

    st.divider()
    st.subheader("API ì„¤ì •")
    api_key_input = st.text_input("OpenAI API í‚¤", type="password", value=st.session_state.openai_api_key)
    if api_key_input:
        st.session_state.openai_api_key = api_key_input
        # ë¸Œë¼ìš°ì € ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì— ì €ì¥ ìš”ì²­
        components.html(
            f'''<script>
               window.parent.postMessage({{type:'saveKey',key:'{api_key_input}'}}, '*');
             </script>''',
            height=0,
        )
    st.divider()

    if st.session_state.analysis_results:
        # ê²°ê³¼ë¥¼ ë‹¤ìš´ë¡œë“œí•  CSV ìƒì„±
        timestamp = format_timestamp(datetime.now())
        df = normalize_logs(process_log(st.session_state.logs))
        buffer = export_results(df, st.session_state.analysis_results)
        st.download_button(
            label="CSV ë‹¤ìš´ë¡œë“œ", data=buffer,
            file_name=f"analysis_{timestamp}.csv", mime="text/csv"
        )

# ë©”ì¸ í™”ë©´
st.title("AI ë¡œê·¸ ë¶„ì„ê¸° ë° GPT ì§€ì› ì‹œìŠ¤í…œ")
st.markdown("ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ AI ê¸°ë°˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

# ë°ì´í„° ì…ë ¥ ì²˜ë¦¬
if source_option == "íŒŒì¼ ì—…ë¡œë“œ":
    uploaded_files = st.file_uploader("ë¡œê·¸ íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "log", "csv"], accept_multiple_files=True)
    if uploaded_files:
        st.session_state.uploaded_files = uploaded_files
        file_names = [f.name for f in uploaded_files]
        selected_name = st.selectbox("íŒŒì¼ ì„ íƒ", file_names)
        selected_file = next((f for f in uploaded_files if f.name == selected_name), None)
        if selected_file:
            content = StringIO(selected_file.getvalue().decode("utf-8")).read()
            st.session_state.logs = content
            st.success(f"{selected_name} íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

elif source_option == "í…ìŠ¤íŠ¸ ì…ë ¥":
    log_input = st.text_area("ë¶„ì„í•  ë¡œê·¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=200)
    if log_input:
        st.session_state.logs = log_input
        st.success("ë¡œê·¸ë¥¼ ìƒíƒœì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

elif source_option == "ìƒ˜í”Œ ë°ì´í„°":
    if st.button("ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ"):
        try:
            with open("data/sample_logs.txt", "r") as f:
                st.session_state.logs = f.read()
            st.success("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ë¡œê·¸ í‘œì‹œ ë° ë¶„ì„ ì‹œì‘
if st.session_state.logs:
    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ì›ë³¸ ë¡œê·¸")
        with st.expander("ì›ë³¸ ë¡œê·¸ ë³´ê¸°", expanded=True):
            st.text_area("ë¡œê·¸ ë‚´ìš©",
                         value=st.session_state.logs[:2000] + ("\n..." if len(st.session_state.logs) > 2000 else ""),
                         height=400, disabled=True)

    with col2:
        st.subheader("ì²˜ë¦¬ëœ ë¡œê·¸")
        processed_logs = process_log(st.session_state.logs)
        if processed_logs.empty:
            processed_logs = process_text_logs(st.session_state.logs)
            st.warning("ê¸°ë³¸ íŒŒì„œë¡œ ë¡œê·¸ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ì–´ í…ìŠ¤íŠ¸ íŒŒì„œë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        with st.expander("ì²˜ë¦¬ëœ ë¡œê·¸ ë³´ê¸°", expanded=True):
            st.dataframe(processed_logs, use_container_width=True)

    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    analyze_button = st.button("GPTë¡œ ë¡œê·¸ ë¶„ì„í•˜ê¸°")
    if analyze_button:
        if not st.session_state.openai_api_key:
            st.error("ë¨¼ì € OpenAI API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state.is_analyzing = True

    # ë¶„ì„ ìˆ˜í–‰
    if st.session_state.is_analyzing:
        # ì²˜ë¦¬ëœ ë¡œê·¸ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì—ëŸ¬ í‘œì‹œ
        if processed_logs.empty:
            st.error("ì²˜ë¦¬ëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë¡œê·¸ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
            st.session_state.is_analyzing = False
        else:
            normalized_logs = normalize_logs(processed_logs)
            with st.spinner("AIê°€ ë¡œê·¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                # í”„ë¡œê·¸ë ˆìŠ¤ ë°” í‘œì‹œ
                progress_bar = st.progress(0)
                for i in range(100):
                    time.sleep(0.05)  # ì‹¤ì œ API í˜¸ì¶œ ì‹œ ì´ ë¶€ë¶„ì€ ì œê±°
                    progress_bar.progress(i + 1)

                # ëª¨ë¸ ì˜µì…˜ ë°˜ì˜: ìƒˆë¡œìš´ GPTAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
                analyzer = GPTAnalyzer(api_key=st.session_state.openai_api_key, model=model_option,
                                       language=st.session_state.response_language)
                gpt_results = analyzer.analyze_with_retry(normalized_logs)

                # ê²°ê³¼ ì €ì¥
                st.session_state.analysis_results = gpt_results
                st.session_state.detailed_analysis_history = []  # ìƒˆë¡œìš´ ë©”ì¸ ë¶„ì„ ì‹œ ê¸°ì¡´ ìƒì„¸ ë¶„ì„ ì´ë ¥ ì´ˆê¸°í™”
                st.session_state.is_analyzing = False
                st.session_state.last_analyzed = datetime.now()

                # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì™„ë£Œ í›„ ì œê±°
                progress_bar.empty()

                st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if st.session_state.analysis_results:
        st.header("ë¶„ì„ ê²°ê³¼")
        st.markdown(f"*ë§ˆì§€ë§‰ ë¶„ì„: {format_timestamp(st.session_state.last_analyzed)}*")

        results = st.session_state.analysis_results

        # ë©”ì¸ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ì¤€ë¹„
        timestamp_download = datetime.now().strftime("%Y%m%d_%H%M%S")
        df_main_download = normalize_logs(process_log(st.session_state.logs))
        buffer_main_csv = export_results(df_main_download, results)

        # íƒ­ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
        tab1, tab2, tab3, tab4 = st.tabs(["ìš”ì•½", "ìƒì„¸ ë¶„ì„", "ì‹œê°í™”", "JSON"])

        with tab1:
            st.subheader("ì£¼ìš” ë°œê²¬ì‚¬í•­")
            st.markdown(f"**ë¬¸ì œ ìœ í˜•:** {results['error_type']}")
            try:
                severity_int = int(results.get('severity', 1))
            except ValueError:
                severity_int = 1
            st.markdown(f"**ìœ„í—˜ë„:** {'ğŸ”´' * severity_int} ({severity_int}/5)")
            st.markdown(f"**ê·¼ë³¸ ì›ì¸:** {results['root_cause']}")
            st.markdown(f"**í•´ê²° ë°©ì•ˆ:** {results['solution']}")

            # ë©”ì¸ ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ
            st.download_button(
                label="ë©”ì¸ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                data=buffer_main_csv,
                file_name=f"main_analysis_{timestamp_download}.csv",
                mime="text/csv"
            )

        with tab2:
            st.subheader("ìƒì„¸ ë¶„ì„")
            # ê¸°ë³¸ ë¶„ì„ ìš”ì•½ í‘œì‹œ
            st.markdown(f"**ìš”ì•½:** {results.get('summary', '')}")

            # ì¶”ê°€ ë¡œê·¸ í†µí•© (ê¸°ì¡´ ì—…ë¡œë“œ íŒŒì¼ ì„ íƒ + ìƒˆ íŒŒì¼ ì—…ë¡œë“œ + í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°)
            existing_files = st.session_state.get("uploaded_files", [])
            if existing_files:
                # ê¸°ë³¸ìœ¼ë¡œ ëª¨ë“  ì—…ë¡œë“œëœ íŒŒì¼ ì„ íƒ
                selected_existing = st.multiselect(
                    "ê¸°ì¡´ ì—…ë¡œë“œëœ ë¡œê·¸ ì„ íƒ",
                    options=[f.name for f in existing_files],
                    default=[f.name for f in existing_files],
                    key="detail_existing"
                )
            else:
                selected_existing = []
            new_files = st.file_uploader("ìƒˆë¡œìš´ ë¡œê·¸ íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "log", "csv"], accept_multiple_files=True,
                                         key="detail_new_files")
            new_text = st.text_area("ì¶”ê°€ ë¡œê·¸ ë³µì‚¬/ë¶™ì—¬ë„£ê¸°", height=150, key="detail_text")

            # ì¶”ê°€ ì„¸ë¶€ ë¶„ì„ ìš”ì²­ UI
            st.markdown("#### ì¶”ê°€ ë¶„ì„ ìš”ì²­")
            detail_query = st.text_input("ì„¸ë¶€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", key="detail_query")
            if st.button("ì„¸ë¶€ ë¶„ì„ ìš”ì²­", key="detail_analyze"):
                if not st.session_state.openai_api_key:
                    st.error("ë¨¼ì € OpenAI API í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.")
                else:
                    # ì„¸ë¶€ ë¡œê·¸ ë° ì›ë³¸ ë¡œê·¸ í†µí•© í›„ ë¶„ì„
                    analyzer = GPTAnalyzer(api_key=st.session_state.openai_api_key, model=model_option,
                                           language=st.session_state.response_language)
                    raw_combined = st.session_state.logs or ""
                    # ê¸°ì¡´ ì—…ë¡œë“œëœ íŒŒì¼ ë‚´ìš© ì¶”ê°€
                    for name in selected_existing:
                        f = next((f for f in existing_files if f.name == name), None)
                        if f:
                            raw_combined += "\n" + f.getvalue().decode("utf-8")
                    # ìƒˆë¡œìš´ íŒŒì¼ ë‚´ìš© ì¶”ê°€
                    if new_files:
                        for f in new_files:
                            raw_combined += "\n" + f.getvalue().decode("utf-8")
                    # í…ìŠ¤íŠ¸ ì…ë ¥ ì¶”ê°€
                    if new_text:
                        raw_combined += "\n" + new_text
                    # AI íŒŒì„œë¡œ ë¨¼ì € êµ¬ì¡°í™” ì‹œë„
                    parsed_entries = analyzer.parse_logs(raw_combined)
                    if parsed_entries:
                        df_combined = pd.DataFrame(parsed_entries)
                    else:
                        # ê¸°ë³¸/í…ìŠ¤íŠ¸ íŒŒì„œ í´ë°±
                        df_combined = process_log(raw_combined)
                        if df_combined.empty:
                            df_combined = process_text_logs(raw_combined)
                    df_combined = normalize_logs(df_combined)
                    detail_res = analyzer.analyze_with_retry(df_combined, specific_query=detail_query)
                    # ê²°ê³¼ë¥¼ ì´ë ¥ì— ì¶”ê°€í•˜ì—¬ ì ì§„ì  ë¶„ì„ ì§€ì›
                    st.session_state.detailed_analysis_history.append({'query': detail_query, 'result': detail_res})

            # ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ í‘œì‹œ (í˜ì´ì§€ë³„)
            if st.session_state.detailed_analysis_history:
                detail_tabs = st.tabs([f"{i + 1}. {entry.get('query', '')}" for i, entry in
                                       enumerate(st.session_state.detailed_analysis_history)])
                for tab, entry in zip(detail_tabs, st.session_state.detailed_analysis_history):
                    with tab:
                        da = entry['result']
                        st.markdown(f"**ë¬¸ì œ ìœ í˜•:** {da.get('error_type', '')}")
                        try:
                            sev = int(da.get('severity', 1))
                        except:
                            sev = 1
                        st.markdown(f"**ìœ„í—˜ë„:** {'ğŸ”´' * sev} ({sev}/5)")
                        st.markdown(f"**ê·¼ë³¸ ì›ì¸:** {da.get('root_cause', '')}")
                        st.markdown(f"**í•´ê²° ë°©ì•ˆ:** {da.get('solution', '')}")
                        patterns = da.get('patterns', [])
                        if patterns:
                            st.markdown("**ì£¼ëª©í•  íŒ¨í„´:**")
                            for p in patterns:
                                st.markdown(f"- {p}")
                        summary = da.get('summary', '')
                        if summary:
                            st.markdown("**ìš”ì•½:**")
                            st.markdown(summary)
                # ì„¸ë¶€ ë¶„ì„ ì „ì²´ ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ
                hist_json = json.dumps(st.session_state.detailed_analysis_history, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ì„¸ë¶€ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (JSON)",
                    data=hist_json,
                    file_name=f"detailed_analysis_{timestamp_download}.json",
                    mime="application/json"
                )
            else:
                st.write("ì„¸ë¶€ ë¶„ì„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")

            # ê¸°ì¡´ ì˜í–¥ ì‹œìŠ¤í…œ ì •ë³´
            if 'affected_systems' in results:
                st.subheader("ì˜í–¥ ë°›ëŠ” ì‹œìŠ¤í…œ")
                for system in results['affected_systems']:
                    st.markdown(f"- {system}")

        with tab3:
            st.subheader("ë¡œê·¸ ì‹œê°í™”")

            # ì‹œê°í™” ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
            if 'time_series_data' in results:
                st.subheader("ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë°œìƒ ë¹ˆë„")
                fig = plot_log_frequency(results['time_series_data'], chart_type)
                st.plotly_chart(fig, use_container_width=True)

            if 'error_distribution' in results:
                st.subheader("ì˜¤ë¥˜ ìœ í˜• ë¶„í¬")
                fig = plot_error_distribution(results['error_distribution'], chart_type)
                st.plotly_chart(fig, use_container_width=True)

        with tab4:
            st.subheader("ì›ì‹œ JSON ë°ì´í„°")
            st.json(results)

# ë„ì›€ë§ ì„¹ì…˜
with st.expander("ì‚¬ìš© ë„ì›€ë§", expanded=False):
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²•
    1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ì†ŒìŠ¤ì™€ ë¶„ì„ ì„¤ì •ì„ ì„ íƒí•˜ì„¸ìš”.
    2. ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë¡œê·¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    3. 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ GPT ê¸°ë°˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.
    4. ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ê²½ìš° ë‚´ë³´ë‚´ê¸°ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

    ### ì§€ì›ë˜ëŠ” ë¡œê·¸ í˜•ì‹
    - ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¡œê·¸
    - syslog í˜•ì‹
    - JSON í˜•ì‹ ë¡œê·¸
    - CSV í˜•ì‹ ë¡œê·¸

    ### ë¶„ì„ ê²°ê³¼ í•´ì„
    - **ìš”ì•½ íƒ­**: ì£¼ìš” ë¬¸ì œì™€ í•´ê²° ë°©ì•ˆì„ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤.
    - **ìƒì„¸ ë¶„ì„ íƒ­**: ì‹¬ì¸µì ì¸ ë¬¸ì œ ì§„ë‹¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    - **ì‹œê°í™” íƒ­**: ë¡œê·¸ íŒ¨í„´ê³¼ ì˜¤ë¥˜ ë¶„í¬ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
    - **JSON íƒ­**: ë¶„ì„ ê²°ê³¼ì˜ ì›ì‹œ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """)

# í‘¸í„°
st.markdown("---")
st.markdown(
    "Â© 2025 AI ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ | ê°œë°œìì—ê²Œ [ì—°ë½í•˜ê¸°](mailto:admin@nodove.com) | "
    "[ë¬¸ì„œ ë³´ê¸°]('')"
)
