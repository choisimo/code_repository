import streamlit as st
import pandas as pd
from io import StringIO
import time
import json
from datetime import datetime
import os

from log_processor import process_log, normalize_logs
from gpt_analyzer import analyze_with_gpt
from visualization.charts import plot_log_frequency, plot_error_distribution
from utils import format_timestamp, export_results
from config import SIDEBAR_STYLE, THEME_COLORS

# í˜ì´ì§€ ì„¤ì •\
st.set_page_config(
    page_title="AI ë¡œê·¸ ë¶„ì„ê¸°",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown(SIDEBAR_STYLE, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'logs' not in st.session_state:
    st.session_state.logs = None
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None
if 'is_analyzing' not in st.session_state:
    st.session_state.is_analyzing = False
if 'last_analyzed' not in st.session_state:
    st.session_state.last_analyzed = None

# ì‚¬ì´ë“œë°” êµ¬ì„±
with st.sidebar:
    st.title("ğŸ” AI ë¡œê·¸ ë¶„ì„ê¸°")
    st.divider()
    
    st.subheader("ë¡œê·¸ ì†ŒìŠ¤ ì„ íƒ")
    source_option = st.radio(
        "ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
        ["íŒŒì¼ ì—…ë¡œë“œ", "í…ìŠ¤íŠ¸ ì…ë ¥", "ìƒ˜í”Œ ë°ì´í„°"]
    )
    
    st.divider()
    st.subheader("ë¶„ì„ ì„¤ì •")
    temperature = st.slider("GPT ì°½ì˜ì„± ìˆ˜ì¤€", 0.0, 1.0, 0.7, 0.1)
    model_option = st.selectbox(
        "GPT ëª¨ë¸ ì„ íƒ",
        ["gpt-3.5-turbo", "gpt-4"]
    )
    
    st.divider()
    st.subheader("ì‹œê°í™” ì„¤ì •")
    chart_type = st.selectbox(
        "ì°¨íŠ¸ ìœ í˜•",
        ["ë§‰ëŒ€ ì°¨íŠ¸", "ë¼ì¸ ì°¨íŠ¸", "íŒŒì´ ì°¨íŠ¸", "íˆíŠ¸ë§µ"]
    )
    
    st.divider()
    if st.session_state.analysis_results:
        if st.button("ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"):
            timestamp = format_timestamp(datetime.now())
            filename = export_results(st.session_state.analysis_results, timestamp)
            st.success(f"ê²°ê³¼ë¥¼ {filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# ë©”ì¸ í™”ë©´
st.title("AI ë¡œê·¸ ë¶„ì„ê¸° ë° GPT ì§€ì› ì‹œìŠ¤í…œ")
st.markdown("ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ AI ê¸°ë°˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")

# ë°ì´í„° ì…ë ¥ ì²˜ë¦¬
if source_option == "íŒŒì¼ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("ë¡œê·¸ íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "log", "csv"])
    if uploaded_file is not None:
        content = StringIO(uploaded_file.getvalue().decode("utf-8")).read()
        st.session_state.logs = content
        st.success("íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        
elif source_option == "í…ìŠ¤íŠ¸ ì…ë ¥":
    log_input = st.text_area("ë¶„ì„í•  ë¡œê·¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", height=200)
    if st.button("ë¡œê·¸ ì œì¶œ") and log_input:
        st.session_state.logs = log_input
        st.success("ë¡œê·¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì œì¶œí–ˆìŠµë‹ˆë‹¤.")
        
elif source_option == "ìƒ˜í”Œ ë°ì´í„°":
    if st.button("ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ"):
        try:
            with open("data/sample_logs.txt", "r") as f:
                st.session_state.logs = f.read()
            st.success("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ë¡œê·¸ í‘œì‹œ ë° ë¶„ì„ ì‹œì‘
if st.session_state.logs:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ì›ë³¸ ë¡œê·¸")
        with st.expander("ì›ë³¸ ë¡œê·¸ ë³´ê¸°", expanded=True):
            st.text_area("ë¡œê·¸ ë‚´ìš©", value=st.session_state.logs[:2000] + ("\n..." if len(st.session_state.logs) > 2000 else ""), height=400, disabled=True)
    
    with col2:
        st.subheader("ì²˜ë¦¬ëœ ë¡œê·¸")
        processed_logs = process_log(st.session_state.logs)
        with st.expander("ì²˜ë¦¬ëœ ë¡œê·¸ ë³´ê¸°", expanded=True):
            st.dataframe(processed_logs, use_container_width=True)
    
    # ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
    analyze_button = st.button("GPTë¡œ ë¡œê·¸ ë¶„ì„í•˜ê¸°")
    if analyze_button:
        st.session_state.is_analyzing = True
        
    # ë¶„ì„ ìˆ˜í–‰
    if st.session_state.is_analyzing:
        normalized_logs = normalize_logs(processed_logs)
        
        with st.spinner("AIê°€ ë¡œê·¸ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            # í”„ë¡œê·¸ë ˆìŠ¤ ë°” í‘œì‹œ
            progress_bar = st.progress(0)
            for i in range(100):
                time.sleep(0.05)  # ì‹¤ì œ API í˜¸ì¶œ ì‹œ ì´ ë¶€ë¶„ì€ ì œê±°
                progress_bar.progress(i + 1)
                
            # GPT ë¶„ì„ í˜¸ì¶œ
            gpt_results = analyze_with_gpt(
                normalized_logs, 
                temperature=temperature,
                model=model_option
            )
            
            # ê²°ê³¼ ì €ì¥
            st.session_state.analysis_results = gpt_results
            st.session_state.is_analyzing = False
            st.session_state.last_analyzed = datetime.now()
            
            # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì™„ë£Œ í›„ ì œê±°
            progress_bar.empty()
            
            st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if st.session_state.analysis_results:
        st.header("ë¶„ì„ ê²°ê³¼")
        st.markdown(f"*ë§ˆì§€ë§‰ ë¶„ì„: {format_timestamp(st.session_state.last_analyzed)}*")
        
        results = st.session_state.analysis_results
        
        # íƒ­ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
        tab1, tab2, tab3, tab4 = st.tabs(["ìš”ì•½", "ìƒì„¸ ë¶„ì„", "ì‹œê°í™”", "JSON"])
        
        with tab1:
            st.subheader("ì£¼ìš” ë°œê²¬ì‚¬í•­")
            st.markdown(f"**ë¬¸ì œ ìœ í˜•:** {results['error_type']}")
            st.markdown(f"**ìœ„í—˜ë„:** {'ğŸ”´' * results['severity']} ({results['severity']}/5)")
            st.markdown(f"**ê·¼ë³¸ ì›ì¸:** {results['root_cause']}")
            st.markdown(f"**í•´ê²° ë°©ì•ˆ:** {results['solution']}")
        
        with tab2:
            st.subheader("ìƒì„¸ ë¶„ì„")
            st.write(results.get('detailed_analysis', 'ìƒì„¸ ë¶„ì„ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'))
            
            if 'affected_systems' in results:
                st.subheader("ì˜í–¥ ë°›ëŠ” ì‹œìŠ¤í…œ")
                for system in results['affected_systems']:
                    st.markdown(f"- {system}")
        
        with tab3:
            st.subheader("ë¡œê·¸ ì‹œê°í™”")
            
            # ì‹œê°í™” ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
            if 'time_series_data' in results:
                st.subheader("ì‹œê°„ëŒ€ë³„ ë¡œê·¸ ë°œìƒ ë¹ˆë„")
                fig = plot_log_frequency(results['time_series_data'], chart_type)
                st.plotly_chart(fig, use_container_width=True)
            
            if 'error_distribution' in results:
                st.subheader("ì˜¤ë¥˜ ìœ í˜• ë¶„í¬")
                fig = plot_error_distribution(results['error_distribution'], chart_type)
                st.plotly_chart(fig, use_container_width=True)
        
        with tab4:
            st.subheader("ì›ì‹œ JSON ë°ì´í„°")
            st.json(results)

# ë„ì›€ë§ ì„¹ì…˜
with st.expander("ì‚¬ìš© ë„ì›€ë§", expanded=False):
    st.markdown("""
    ### ì‚¬ìš© ë°©ë²•
    1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„° ì†ŒìŠ¤ì™€ ë¶„ì„ ì„¤ì •ì„ ì„ íƒí•˜ì„¸ìš”.
    2. ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë¡œê·¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    3. 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ GPT ê¸°ë°˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.
    4. ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ ê²½ìš° ë‚´ë³´ë‚´ê¸°ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.
    
    ### ì§€ì›ë˜ëŠ” ë¡œê·¸ í˜•ì‹
    - ê¸°ë³¸ í…ìŠ¤íŠ¸ ë¡œê·¸
    - syslog í˜•ì‹
    - JSON í˜•ì‹ ë¡œê·¸
    - CSV í˜•ì‹ ë¡œê·¸
    
    ### ë¶„ì„ ê²°ê³¼ í•´ì„
    - **ìš”ì•½ íƒ­**: ì£¼ìš” ë¬¸ì œì™€ í•´ê²° ë°©ì•ˆì„ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤.
    - **ìƒì„¸ ë¶„ì„ íƒ­**: ì‹¬ì¸µì ì¸ ë¬¸ì œ ì§„ë‹¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    - **ì‹œê°í™” íƒ­**: ë¡œê·¸ íŒ¨í„´ê³¼ ì˜¤ë¥˜ ë¶„í¬ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.
    - **JSON íƒ­**: ë¶„ì„ ê²°ê³¼ì˜ ì›ì‹œ ë°ì´í„°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """)

# í‘¸í„°
st.markdown("---")
st.markdown(
    "Â© 2023 AI ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ | ê°œë°œìì—ê²Œ [ì—°ë½í•˜ê¸°](mailto:example@example.com) | "
    "[ë¬¸ì„œ ë³´ê¸°](https://github.com/username/ai-log-analyzer)"
)
