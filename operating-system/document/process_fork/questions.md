# 4번 주제: 프로세스 관리 문제

## 문제 1
프로세스(process)와 프로그램(program)의 차이점을 설명하고, 하나의 프로그램에서 여러 개의 프로세스가 생성되는 예시를 제시하시오.

**답변:**
프로그램은 디스크에 저장된 실행 파일과 같은 수동적 엔티티(passive entity)로, 명령어와 데이터의 집합입니다. 반면 프로세스는 능동적 엔티티(active entity)로, 실행 중인 프로그램의 인스턴스입니다. 프로세스는 CPU 시간, 메모리, 파일, I/O 장치 등의 자원을 필요로 하며, 프로그램 카운터(PC)를 갖고 있어 다음에 실행할 명령어를 지정합니다.

하나의 프로그램에서 여러 프로세스가 생성되는 예시:
- 웹 브라우저 프로그램이 각 탭마다 별도의 프로세스를 생성
- 워드 프로세서가 여러 문서를 각각 다른 프로세스로 처리
- 서버 프로그램이 각 클라이언트 연결마다 새로운 프로세스 생성
- 이메일 클라이언트가 백그라운드 동기화와 UI를 위한 별도 프로세스 실행

**해설:**
프로그램과 프로세스의 구분은 운영체제의 기본 개념입니다. 프로그램은 정적인 실행 파일로 저장장치에 있지만, 프로세스는 그 프로그램이 메모리에 로드되어 CPU에 의해 실행되는 동적 객체입니다. 동일한 프로그램에서 여러 프로세스가 생성될 수 있으며, 각 프로세스는 독립적인 실행 경로를 가집니다. 운영체제는 프로세스에 자원을 할당하고, 생성부터 종료까지의 생명주기를 관리합니다. 현대 운영체제에서는 프로세스 간 통신(IPC) 메커니즘을 제공하여 프로세스들이 서로 협력할 수 있게 합니다.

## 문제 2
프로세스의 주요 상태(state)들을 나열하고, 각 상태 간 전이가 발생하는 조건에 대해 설명하시오.

**답변:**
프로세스의 주요 상태:

1. 생성(New) 상태:
   - 프로세스가 생성 중인 상태
   - 전이 조건: 시스템이 프로세스 생성을 완료하면 준비 상태로 전이

2. 준비(Ready) 상태:
   - CPU를 할당받기 위해 대기 중인 상태
   - 전이 조건: 스케줄러가 프로세스 선택 시 실행 상태로 전이

3. 실행(Running) 상태:
   - CPU를 할당받아 명령어를 실행 중인 상태
   - 전이 조건 1: 시간 할당량 소진 또는 선점 시 준비 상태로 전이
   - 전이 조건 2: I/O 요청이나 이벤트 대기 시 대기 상태로 전이
   - 전이 조건 3: 프로세스 종료 시 종료 상태로 전이

4. 대기(Waiting/Blocked) 상태:
   - I/O 완료나 이벤트 발생을 기다리는 상태
   - 전이 조건: I/O 완료나 기다리던 이벤트 발생 시 준비 상태로 전이

5. 종료(Terminated) 상태:
   - 실행이 완료되었거나 오류로 종료된 상태
   - 전이 조건: 시스템이 프로세스 자원 회수 후 프로세스 제거

**해설:**
프로세스 상태 전이도(process state transition diagram)는 프로세스 생명주기와 관리 방식을 이해하는 데 중요합니다. 운영체제는 각 프로세스의 상태를 PCB(Process Control Block)에 기록하고, 상태에 따라 다른 큐(ready queue, wait queue 등)에서 관리합니다. 특히 CPU 스케줄링은 주로 준비 상태의 프로세스 중에서 다음 실행할 프로세스를 선택합니다. 대기 상태의 프로세스는 요청한 이벤트가 발생하면 다시 준비 상태로 돌아가야만 CPU를 얻을 기회가 있습니다. 이러한 상태 전이 관리를 통해 운영체제는 다중 프로그래밍과 시분할 시스템을 효율적으로 구현할 수 있습니다.

## 문제 3
프로세스 제어 블록(PCB)에 저장되는 주요 정보들을 나열하고, 이 정보들이 어떻게 활용되는지 설명하시오.

**답변:**
프로세스 제어 블록(PCB)에 저장되는 주요 정보:

1. 프로세스 식별 정보:
   - 프로세스 ID(PID)
   - 부모 프로세스 ID(PPID)
   - 사용자 ID

2. 프로세스 상태 정보:
   - 현재 프로세스 상태(실행, 준비, 대기 등)
   - 이벤트 정보(대기 중인 경우)

3. 프로그램 제어 정보:
   - 프로그램 카운터(다음 실행할 명령어 주소)
   - CPU 레지스터 값
   - 스택 포인터

4. CPU 스케줄링 정보:
   - 프로세스 우선순위
   - 스케줄링 큐 포인터
   - CPU 사용 시간과 제한 시간

5. 메모리 관리 정보:
   - 기준 레지스터(base register) 값
   - 한계 레지스터(limit register) 값
   - 페이지 테이블 또는 세그먼트 테이블 정보

6. 자원 사용 정보:
   - 열린 파일 목록
   - 할당된 I/O 장치 목록
   - 사용 중인 메모리 자원

7. 회계 정보:
   - CPU 사용 시간
   - 실제 사용 시간
   - 시간 제한

이 정보들의 활용:
- 컨텍스트 스위칭: CPU가 다른 프로세스로 전환할 때 현재 상태 저장 및 복원
- 스케줄링: 우선순위와 실행 시간을 기반으로 CPU 할당 결정
- 동기화: 프로세스 간 종속성 및 통신 관리
- 메모리 관리: 프로세스의 주소 공간 접근 제어
- 프로세스 계보 추적: 부모-자식 관계 유지

**해설:**
PCB는 운영체제가 프로세스를 관리하는 데 필요한 모든 정보를 담고 있는 데이터 구조로, 프로세스의 "메타데이터"라고 볼 수 있습니다. 운영체제는 각 프로세스마다 PCB를 생성하여 관리하며, 이를 통해 다중 프로그래밍 환경에서 여러 프로세스를 효과적으로 관리합니다. PCB는 프로세스가 CPU를 양보할 때 현재 상태를 저장하고, 나중에 다시 실행될 때 상태를 복원하는 컨텍스트 스위칭의 핵심 요소입니다. 또한 운영체제는 PCB 정보를 기반으로 자원 할당, 스케줄링, 동기화 등 다양한 관리 작업을 수행합니다. PCB 구조는 운영체제마다 다를 수 있지만, 위에 나열된 정보들은 대부분의 운영체제에서 공통적으로 관리됩니다.

## 문제 4
프로세스 생성 시 부모 프로세스와 자식 프로세스 간에 자원이 공유되는 방식에 대해 설명하고, 이와 관련된 대표적인 시스템 콜들을 소개하시오.

**답변:**
프로세스 생성 시 부모-자식 프로세스 간 자원 공유 방식:

1. 자원 복제 방식:
   - 자식 프로세스가 부모 프로세스의 자원을 복제하여 각자 독립적인 복사본 소유
   - 부모와 자식이 독립적으로 실행되며 간섭 없음
   - 예: UNIX의 전통적인 fork() 시스템 콜

2. 자원 공유 방식:
   - 부모와 자식이 특정 자원을 공유
   - 변경 사항이 서로에게 영향을 미침
   - 예: 공유 메모리 세그먼트, 열린 파일

3. 부분 공유 방식:
   - 일부 자원은 공유하고 일부는 복제
   - 예: 코드 세그먼트(공유), 데이터 세그먼트(복제)

관련 시스템 콜:

1. fork():
   - UNIX/Linux 계열에서 사용
   - 호출한 프로세스의 거의 완전한 복사본인 자식 프로세스 생성
   - 자식은 부모와 동일한 코드를 실행하지만 부모와 다른 반환값 받음
   - 기본적으로 모든 자원을 복제하지만 Copy-on-Write 최적화 사용

2. exec():
   - 현재 프로세스의 메모리 이미지를 새 프로그램으로 덮어씀
   - 보통 fork() 후 자식 프로세스에서 호출하여 새 프로그램 로드
   - 변형: execl(), execv(), execle(), execve() 등

3. wait():
   - 부모 프로세스가 자식 프로세스 종료를 기다림
   - 자식 프로세스의 종료 상태 수집
   - 부모-자식 간 동기화 메커니즘 제공

4. CreateProcess():
   - Windows 운영체제에서 사용
   - fork()+exec()와 달리 단일 호출로 새 프로세스 생성
   - 다양한 생성 옵션을 매개변수로 지정 가능

**해설:**
프로세스 생성 모델은 운영체제마다 다릅니다. UNIX/Linux 계열은 fork() 시스템 콜을 통해 프로세스를 생성하고, 필요에 따라 exec() 계열 함수로 새 프로그램을 로드합니다. 이 두 단계 접근법은 유연성을 제공하지만, Windows는 CreateProcess()라는 단일 시스템 콜을 사용합니다.

현대 시스템에서는 성능 최적화를 위해 Copy-on-Write(COW) 기법을 사용합니다. fork() 호출 시 물리적으로 메모리를 복사하는 대신, 부모와 자식이 같은 물리적 페이지를 공유하다가 어느 한쪽이 페이지를 수정할 때만 실제 복사가 이루어집니다. 이로써 불필요한 메모리 복사를 줄이고 프로세스 생성 속도를 높입니다.

자원 공유 정도는 프로세스 간 통신과 협력 정도에 영향을 미칩니다. 완전히 독립적인 프로세스는 보안과 안정성이 높지만, 자원 공유는 효율성과 통신 용이성을 제공합니다. 운영체제는 이러한 트레이드오프를 고려하여 다양한 프로세스 생성 및 자원 공유 메커니즘을 제공합니다.

## 문제 5
프로세스 스케줄링의 목적과 대표적인 CPU 스케줄링 알고리즘들의 특징을 비교 설명하시오.

**답변:**
프로세스 스케줄링의 목적:
- CPU 활용도 극대화
- 처리량(throughput) 최대화
- 반환 시간(turnaround time) 최소화
- 대기 시간(waiting time) 최소화
- 응답 시간(response time) 개선
- 공정성 보장 및 기아 상태(starvation) 방지

대표적인 CPU 스케줄링 알고리즘:

1. 선입선출(FCFS, First-Come, First-Served):
   - 특징: 도착 순서대로 CPU 할당
   - 장점: 구현 간단, 공정성 보장
   - 단점: 긴 프로세스가 짧은 프로세스 실행 지연(convoy effect), 평균 대기 시간 증가
   - 적합한 환경: 배치 처리 시스템

2. 최단 작업 우선(SJF, Shortest Job First):
   - 특징: CPU 버스트 시간이 가장 짧은 프로세스 먼저 실행
   - 장점: 평균 대기 시간 최소화(이론적 최적)
   - 단점: 실행 시간 예측 어려움, 긴 프로세스 기아 상태 가능성
   - 적합한 환경: 실행 시간 예측이 정확한 환경

3. 우선순위 스케줄링(Priority Scheduling):
   - 특징: 우선순위가 높은 프로세스 먼저 실행
   - 장점: 중요 작업 우선 처리, 시스템 요구사항 반영 가능
   - 단점: 우선순위 낮은 프로세스 기아 상태 가능성
   - 변형: 에이징(aging) 기법으로 기아 상태 방지

4. 라운드 로빈(Round Robin):
   - 특징: 각 프로세스에 동일한 시간 할당량(time quantum) 부여, 순환적 실행
   - 장점: 응답 시간 보장, 공정성, 구현 용이
   - 단점: 시간 할당량 선택에 따른 성능 차이, 컨텍스트 스위칭 오버헤드
   - 적합한 환경: 시분할(time-sharing) 시스템

5. 다단계 큐(Multilevel Queue):
   - 특징: 프로세스를 특성에 따라 여러 큐로 분류, 각 큐마다 다른 스케줄링 알고리즘 적용
   - 장점: 다양한 유형의 프로세스 효율적 처리
   - 단점: 큐 간 우선순위 조정 어려움, 낮은 우선순위 큐 기아 상태 가능성

6. 다단계 피드백 큐(Multilevel Feedback Queue):
   - 특징: 프로세스가 큐 간에 이동 가능, 동작 패턴에 따라 우선순위 조정
   - 장점: 적응적 스케줄링, 다양한 유형의 프로세스 균형 처리
   - 단점: 구현 복잡, 매개변수 설정 어려움
   - 적합한 환경: 다양한 작업이 혼합된 범용 시스템

**해설:**
CPU 스케줄링은 다중 프로그래밍 운영체제의 핵심 기능으로, 여러 프로세스 간에 CPU 시간을 효율적으로 분배하는 메커니즘입니다. 스케줄링 알고리즘의 선택은 시스템의 목적과 워크로드 특성에 따라 달라집니다.

선점형(preemptive) vs 비선점형(non-preemptive) 스케줄링은 중요한 구분점입니다. 선점형은 실행 중인 프로세스를 강제로 중단시키고 다른 프로세스에 CPU를 할당할 수 있는 반면, 비선점형은 프로세스가 자발적으로 CPU를 양보할 때까지 기다립니다. 현대 운영체제는 대부분 선점형 스케줄링을 사용하여 응답성을 높입니다.

실제 운영체제에서는 단일 알고리즘보다는 여러 알고리즘을 조합하여 사용합니다. 예를 들어, Linux의 CFS(Completely Fair Scheduler)는 공정성과 응답성을 모두 고려한 복합 알고리즘을 사용합니다. 스케줄링 성능은 CPU 사용률, 처리량, 대기 시간, 응답 시간 등 다양한 지표로 평가되며, 이상적인 알고리즘은 이러한 지표들 간의 적절한 균형을 달성해야 합니다.

## 문제 6
프로세스 간 통신(IPC, Inter-Process Communication)의 다양한 방법들을 비교 설명하고, 각 방법의 장단점을 설명하시오.

**답변:**
프로세스 간 통신(IPC)의 다양한 방법:

1. 파이프(Pipe):
   - 특징: 단방향 통신 채널, 주로 부모-자식 프로세스 간 통신에 사용
   - 구현: UNIX의 pipe() 시스템 콜
   - 장점: 간단한 구현, 동기화 자동 제공
   - 단점: 단방향 통신, 관련 있는 프로세스 간에만 사용 가능
   - 사용 예: 쉘 명령어 파이프라인(ls | grep)

2. 명명된 파이프(Named Pipe 또는 FIFO):
   - 특징: 파일 시스템에 이름이 있는 영구적 파이프
   - 구현: mkfifo() 또는 mknod() 시스템 콜
   - 장점: 관련 없는 프로세스 간에도 통신 가능
   - 단점: 여전히 단방향 통신, 구조화된 데이터 전송에 제한적
   - 사용 예: 클라이언트-서버 통신 채널

3. 메시지 큐(Message Queue):
   - 특징: 구조화된 메시지 교환, 큐 형태로 메시지 저장
   - 구현: msgget(), msgsnd(), msgrcv() 시스템 콜
   - 장점: 비동기 통신, 메시지 타입 및 우선순위 지원
   - 단점: 메시지 크기 제한, 상대적으로 느린 속도
   - 사용 예: 클라이언트-서버 통신, 작업 큐

4. 공유 메모리(Shared Memory):
   - 특징: 여러 프로세스가 동일한 메모리 영역 접근
   - 구현: shmget(), shmat() 시스템 콜 또는 mmap()
   - 장점: 가장 빠른 IPC 방식, 대용량 데이터 교환에 효율적
   - 단점: 동기화 메커니즘 별도 필요, 데이터 구조 관리 복잡
   - 사용 예: 데이터베이스 시스템, 멀티미디어 애플리케이션

5. 세마포어(Semaphore):
   - 특징: 공유 자원 접근 제어 메커니즘
   - 구현: semget(), semop() 시스템 콜
   - 장점: 동기화 제공, 상호 배제(mutual exclusion) 보장
   - 단점: 주로 동기화용으로 대용량 데이터 전송에 비효율적
   - 사용 예: 공유 자원 접근 제어, 생산자-소비자 문제 해결

6. 소켓(Socket):
   - 특징: 네트워크 통신 인터페이스, 로컬 및 원격 통신 가능
   - 구현: socket(), bind(), listen(), accept() 등
   - 장점: 다양한 통신 프로토콜 지원, 분산 시스템 구현 가능
   - 단점: 상대적으로 오버헤드 큼, 설정 복잡
   - 사용 예: 네트워크 서비스, 분산 애플리케이션

7. 신호(Signal):
   - 특징: 비동기적 이벤트 알림 메커니즘
   - 구현: signal(), kill() 시스템 콜
   - 장점: 간단한 이벤트 알림, 인터럽트와 유사
   - 단점: 제한된 정보 전달, 신뢰성 문제
   - 사용 예: 프로세스 종료 요청, 타이머 알림

**해설:**
프로세스 간 통신은 독립적인 프로세스들이 데이터를 교환하고 활동을 동기화하는 메커니즘입니다. 각 IPC 방식은 속도, 유연성, 구현 복잡성 측면에서 서로 다른 특성을 가지며, 적절한 선택은 통신 요구사항에 따라 달라집니다.

공유 메모리는 가장 빠른 IPC 방식이지만, 동기화 문제를 해결해야 하며 이를 위해 세마포어나 뮤텍스와 같은 별도의 동기화 메커니즘이 필요합니다. 반면, 메시지 전달 방식(파이프, 메시지 큐 등)은 구현이 단순하고 동기화가 내장되어 있지만, 상대적으로 속도가 느립니다.

현대 운영체제는 다양한 IPC 메커니즘을 제공하며, 애플리케이션은 자신의 요구에 맞는 방식을 선택할 수 있습니다. 복잡한 시스템에서는 여러 IPC 메커니즘을 조합하여 사용하는 경우도 많습니다. 예를 들어, 대용량 데이터는 공유 메모리로 전송하고, 제어 신호는 메시지 큐나 세마포어를 통해 처리하는 방식입니다.

## 문제 7
프로세스 동기화 문제인 생산자-소비자 문제(Producer-Consumer Problem)에 대해 설명하고, 세마포어를 사용한 해결 방법을 제시하시오.

**답변:**
생산자-소비자 문제(Producer-Consumer Problem):

생산자-소비자 문제는 프로세스 동기화의 고전적인 문제로, 한 프로세스(생산자)가 데이터를 생성하고 다른 프로세스(소비자)가 그 데이터를 소비하는 상황을 모델링합니다. 생산자와 소비자는 유한한 공유 버퍼를 통해 데이터를 주고받습니다.

주요 제약 조건:
- 생산자는 버퍼가 가득 찼을 때 더 이상 데이터를 생산할 수 없다
- 소비자는 버퍼가 비어있을 때 데이터를 소비할 수 없다
- 데이터는 생산된 순서대로 소비되어야 한다
- 여러 생산자와 소비자가 동시에 활동할 수 있다

이 문제의 핵심은 두 프로세스 간의 적절한 동기화를 통해 데이터 무결성을 유지하고 교착 상태(deadlock)나 기아 상태(starvation)를 방지하는 것입니다.

세마포어를 사용한 해결 방법:

```c
#define BUFFER_SIZE 10

typedef struct {
    // 버퍼 내용과 관련 변수들
    int buffer[BUFFER_SIZE];
    int in;    // 생산자가 다음에 쓸 위치
    int out;   // 소비자가 다음에 읽을 위치
    int count; // 현재 버퍼에 있는 항목 수
} Buffer;

Buffer shared_buffer; // 공유 버퍼

// 세마포어 정의
semaphore mutex = 1;      // 상호 배제를 위한 이진 세마포어
semaphore empty = BUFFER_SIZE; // 빈 슬롯 수를 나타내는 카운팅 세마포어
semaphore full = 0;       // 채워진 슬롯 수를 나타내는 카운팅 세마포어

void producer() {
    int item;
    while (true) {
        item = produce_item(); // 데이터 생성
        
        wait(empty);  // 빈 슬롯 대기
        wait(mutex);  // 버퍼에 대한 상호 배제 획득
        
        // 버퍼에 아이템 추가
        shared_buffer.buffer[shared_buffer.in] = item;
        shared_buffer.in = (shared_buffer.in + 1) % BUFFER_SIZE;
        shared_buffer.count++;
        
        signal(mutex); // 상호 배제 해제
        signal(full);  // 채워진 슬롯 수 증가
    }
}

void consumer() {
    int item;
    while (true) {
        wait(full);   // 채워진 슬롯 대기
        wait(mutex);  // 버퍼에 대한 상호 배제 획득
        
        // 버퍼에서 아이템 제거
        item = shared_buffer.buffer[shared_buffer.out];
        shared_buffer.out = (shared_buffer.out + 1) % BUFFER_SIZE;
        shared_buffer.count--;
        
        signal(mutex); // 상호 배제 해제
        signal(empty); // 빈 슬롯 수 증가
        
        consume_item(item); // 데이터 소비
    }
}
```

**해설:**
생산자-소비자 문제는 여러 프로세스가 공유 자원에 접근할 때 발생할 수 있는 동기화 문제의 대표적인 예입니다. 이 문제를 해결하기 위해서는 세 가지 주요 요구사항을 충족해야 합니다:

1. 상호 배제(Mutual Exclusion): 한 번에 하나의 프로세스만 공유 버퍼를 수정할 수 있어야 합니다. 이를 위해 'mutex' 세마포어를 사용합니다.

2. 동기화(Synchronization): 생산자는 버퍼가 가득 찼을 때 기다려야 하고, 소비자는 버퍼가 비었을 때 기다려야 합니다. 이를 위해 'empty'와 'full' 세마포어를 사용합니다.

3. 공정성(Fairness): 모든 프로세스가 결국에는 진행할 수 있어야 합니다. 세마포어의 정확한 사용은 기아 상태를 방지합니다.

위 코드에서 사용된 wait()/signal() 연산은 각각 P()/V() 또는 sem_wait()/sem_post()라고도 불리며, 세마포어 값을 감소/증가시키는 원자적 연산입니다. 세마포어 값이 0이면 wait() 호출 시 프로세스가 블록되고, signal() 호출은 대기 중인 프로세스를 깨웁니다.

세마포어 순서가 중요합니다. mutex를 먼저 획득하고 empty/full을 기다리면 교착 상태가 발생할 수 있으므로, 먼저 empty/full을 기다린 후 mutex를 획득해야 합니다. 이 패턴은 많은 동기화 문제에 적용될 수 있으며, 운영체제와 병렬 프로그래밍에서 널리 사용됩니다.

## 문제 8
멀티스레드(multi-threaded) 프로세스와 단일스레드(single-threaded) 프로세스의 차이점을 설명하고, 멀티스레딩의 장단점을 논하시오.

**답변:**
멀티스레드 vs 단일스레드 프로세스 차이점:

1. 실행 흐름:
   - 단일스레드: 한 번에 하나의 실행 흐름만 존재
   - 멀티스레드: 여러 실행 흐름이 동시에 존재

2. 프로그램 카운터:
   - 단일스레드: 단일 프로그램 카운터로 다음 명령어 지정
   - 멀티스레드: 각 스레드마다 별도의 프로그램 카운터 존재

3. 스택:
   - 단일스레드: 단일 스택만 사용
   - 멀티스레드: 각 스레드마다 독립적인 스택 보유

4. 자원 공유:
   - 단일스레드: 모든 자원은 단일 실행 흐름에 속함
   - 멀티스레드: 코드, 데이터, 파일 등 대부분의 자원을 공유하지만, 스택과 레지스터는 각 스레드마다 별도로 존재

멀티스레딩의 장점:

1. 응답성(Responsiveness) 향상:
   - 사용자 인터페이스 스레드가 블로킹 작업과 독립적으로 실행되어 응답성 유지
   - 긴 작업을 수행하면서도 사용자 입력 처리 가능

2. 자원 공유(Resource Sharing):
   - 스레드 간 자원 공유가 프로세스 간 공유보다 효율적
   - 명시적인 통신 없이도 데이터 공유 가능

3. 경제성(Economy):
   - 스레드 생성과 컨텍스트 스위칭이 프로세스보다 경제적
   - 메모리와 자원 사용량 절약

4. 확장성(Scalability):
   - 다중 CPU나 코어 환경에서 병렬 실행 가능
   - 작업 분할을 통한 성능 향상

멀티스레딩의 단점:

1. 복잡성 증가:
   - 동기화 문제 처리 필요
   - 데드락, 레이스 컨디션 등 새로운 버그 유형 발생

2. 디버깅 어려움:
   - 비결정적 실행으로 인한 재현 어려움
   - 스레드 간 상호작용 추적 복잡

3. 확장성 제한:
   - 너무 많은 스레드 생성 시 성능 저하
   - 스레드 간 경쟁으로 인한 오버헤드

4. 안정성 이슈:
   - 한 스레드의 문제가 전체 프로세스에 영향
   - 메모리 공유로 인한 취약점 발생 가능

**해설:**
멀티스레딩은 현대 응용 프로그램 설계의 핵심 요소로, 단일 프로세스 내에서 여러 실행 흐름을, 가능하게 합니다. 스레드는 프로세스보다 가벼운 실행 단위로, 프로세스의 자원을 공유하면서도 독립적으로 실행될 수 있습니다.

멀티스레딩의 주요 이점은 다중 코어 환경에서의 병렬 처리, 응답성 향상, 자원 효율성입니다. 특히 I/O 바운드 애플리케이션에서 한 스레드가 I/O를 기다리는 동안 다른 스레드가 CPU를 사용할 수 있어 효율적입니다. 또한 웹 서버와 같은 환경에서 요청당 스레드를 할당하여 동시성을 높일 수 있습니다.

그러나 멀티스레딩은 동기화와 관련된 복잡성을 증가시킵니다. 스레드 간 공유 데이터에 대한 접근을 조율하지 않으면 레이스 컨디션, 데드락, 기아 상태와 같은 문제가 발생할 수 있습니다. 이러한 문제는 뮤텍스, 세마포어, 조건 변수 등의 동기화 메커니즘으로 해결해야 하지만, 이 과정에서 프로그램 복잡성이 증가하고 성능 오버헤드가 발생할 수 있습니다.

현대 프로그래밍에서는 스레드 풀(thread pool), 작업 큐(task queue), 비동기 프로그래밍 등의 방식으로 멀티스레딩의 장점은 최대화하고 단점은 최소화하려는 노력이 계속되고 있습니다.

## 문제 9
교착 상태(deadlock)의 정의와 발생 조건을 설명하고, 교착 상태를 예방하는 방법들에 대해 논하시오.

**답변:**
교착 상태(Deadlock)의 정의:
교착 상태는 두 개 이상의 프로세스가 서로가 보유한 자원을 기다리며 영원히 진행하지 못하는 상황을 말합니다. 각 프로세스는 자신이 보유한 자원을 놓지 않으면서 다른 프로세스가 보유한 자원을 요청하는 상태에 빠지게 됩니다.

교착 상태 발생의 4가지 필요 조건:

1. 상호 배제(Mutual Exclusion):
   - 자원은 한 번에 하나의 프로세스만 사용할 수 있음
   - 다른 프로세스의 사용이 끝날 때까지 접근 불가

2. 점유 대기(Hold and Wait):
   - 프로세스가 이미 자원을 보유한 상태에서 다른 자원을 요청함
   - 요청한 자원이 할당될 때까지 보유 자원을 놓지 않음

3. 비선점(No Preemption):
   - 프로세스에 할당된 자원은 해당 프로세스가 자발적으로 반환할 때까지 강제로 빼앗을 수 없음
   - 자원 사용 완료 전에는 반환 불가

4. 순환 대기(Circular Wait):
   - 프로세스들이 순환 형태로 서로의 자원을 기다림
   - P1→P2→P3→...→Pn→P1 형태의 대기 관계 형성

교착 상태 예방(Prevention) 방법:

1. 상호 배제 조건 제거:
   - 모든 자원을 공유 가능하게 만듦
   - 스풀링(spooling)처럼 가상 장치 개념 도입
   - 단, 본질적으로 상호 배제가 필요한 자원에는 적용 불가

2. 점유 대기 조건 제거:
   - 프로세스가 실행되기 전 필요한 모든 자원을 한꺼번에 요청하고 할당
   - 하나의 자원이라도 할당받지 못하면 어떤 자원도 보유하지 않음
   - 단점: 자원 이용률 저하, 기아 상태 가능성

3. 비선점 조건 제거:
   - 자원을 점유한 프로세스가 다른 자원을 요청했을 때 할당받지 못하면 보유 자원 반환
   - 나중에 모든 필요 자원을 다시 한꺼번에 요청
   - 단점: 모든 자원에 적용 불가, 문맥 교환 비용 증가

4. 순환 대기 조건 제거:
   - 자원에 전체 순서를 부여하고 오름차순으로만 요청 허용
   - 모든 프로세스가 정해진 순서로만 자원 요청하면 순환 불가
   - 단점: 자원 활용도 저하, 응용 프로그램 제약

교착 상태 회피(Avoidance) 방법:

1. 은행원 알고리즘(Banker's Algorithm):
   - 안전 상태(safe state)를 유지하는 자원 할당만 허용
   - 프로세스의 최대 자원 요청량을 미리 알고 있어야 함
   - 항상 교착 상태를 회피할 수 있는 실행 순서가 존재하는지 확인

2. 자원 할당 그래프(Resource Allocation Graph):
   - 자원 요청 시 할당 후에도 사이클이 생기지 않는 경우만 허용
   - 단일 인스턴스 자원에만 효과적

**해설:**
교착 상태는 자원 관리와 프로세스 동기화의 중요한 문제입니다. 교착 상태가 발생하면 관련된 프로세스들은, 외부 개입 없이는 진행할 수 없습니다. 이는 시스템 성능과 가용성에 심각한 영향을 미칠 수 있습니다.

교착 상태 처리에는 네 가지 접근 방식이 있습니다:
1. 예방(Prevention): 네 가지 필요 조건 중 하나 이상을, 원천적으로 제거하여 교착 상태 발생 자체를 방지
2. 회피(Avoidance): 자원 할당 전에 안전성을 검사하여 교착 상태 가능성이 있는 할당 거부
3. 탐지 및 복구(Detection and Recovery): 교착 상태를 감지하고 발생 시 해결
4. 무시(Ignorance): 교착 상태가 잘 일어나지 않는다고 가정하고 특별한 조치를 취하지 않음

실제 운영체제에서는 이러한 방법을 조합하여 사용합니다. 예를 들어, 일부 중요한 자원에 대해서는 예방이나 회피 전략을 사용하고, 덜 중요한 자원은 탐지 및 복구나 무시 전략을 사용할 수 있습니다. 교착 상태 처리 방법의 선택은 시스템의 목적, 자원 특성, 성능 요구사항 등에 따라 달라집니다.

## 문제 10
운영체제에서 문맥 교환(context switching)이란 무엇이며, 이 과정에서 발생하는 오버헤드와 이를 최소화하는 방법에 대해 설명하시오.

**답변:**
문맥 교환(Context Switching)의 정의:
문맥 교환은 CPU가 현재 실행 중인 프로세스나 스레드에서 다른 프로세스나 스레드로 전환하는 과정으로, 이전 프로세스의 상태(문맥)를 저장하고 새 프로세스의 상태를 복원하는 작업을 포함합니다.

문맥(Context)에 포함되는 정보:
- CPU 레지스터 값(일반 레지스터, 프로그램 카운터, 스택 포인터 등)
- 프로세스 상태 정보
- 메모리 관리 정보(페이지 테이블, 세그먼트 테이블 등)
- I/O 상태 정보
- 계정 정보

문맥 교환 과정:
1. 현재 실행 중인 프로세스 A의 상태를 PCB에 저장
2. 프로세스 A를 준비 큐나 대기 큐로 이동
3. 다음 실행할 프로세스 B를 스케줄러가 선택
4. 프로세스 B의 PCB에서 문맥 정보를 CPU 레지스터에 로드
5. 프로세스 B의 주소 공간으로 메모리 맵 전환
6. 프로세스 B 실행 재개

문맥 교환 오버헤드:

1. 직접적 비용:
   - 레지스터 값 저장 및 복원 시간
   - 메모리 관리 단위(MMU) 재구성 시간
   - 캐시 및 TLB 플러시로 인한 시간

2. 간접적 비용:
   - 캐시 지역성(locality) 손실로 인한 캐시 미스 증가
   - 파이프라인 플러시
   - 분기 예측기 상태 손실
   - 페이지 폴트 가능성 증가

3. 프로세스 vs 스레드 문맥 교환:
   - 프로세스 간 문맥 교환: 주소 공간 전환 필요, 더 많은 오버헤드
   - 스레드 간 문맥 교환: 동일 주소 공간 내, 상대적으로 적은 오버헤드

문맥 교환 오버헤드 최소화 방법:

1. 프로세스 설계 최적화:
   - 스레드 사용: 프로세스 간 전환보다 스레드 간 전환이 효율적
   - 스레드 풀(thread pool) 사용: 스레드 생성/소멸 최소화
   - 비동기 I/O와 이벤트 기반 프로그래밍: 불필요한 블로킹 감소

2. 운영체제 수준 최적화:
   - 프로세서 친화도(processor affinity) 활용: 같은 CPU에서 실행 유지
   - 지연 스케줄링(lazy scheduling): 필요할 때만 컨텍스트 스위치
   - 작업 그룹화(batching): 유사한 작업을 함께 처리

3. 하드웨어 활용:
   - 레지스터 윈도우(register windows): 레지스터 세트의 빠른 전환
   - 하드웨어 문맥 교환 지원: 전용 명령어 세트 활용
   - 다중 TLB 태그: 주소 공간 ID로 TLB 플러시 없이 전환

4. 메모리 관리 최적화:
   - 공유 메모리 활용: 프로세스 간 데이터 공유로 전환 감소
   - 큰 페이지 크기(huge pages) 사용: TLB 미스 감소
   - 워킹 세트(working set) 보존: 메모리 지역성 유지

**해설:**
문맥 교환은 멀티태스킹 운영체제의 핵심 메커니즘으로, 여러 프로세스나 스레드가 CPU를 공유할 수 있게 해주지만 상당한 오버헤드를 발생시킵니다. 이 오버헤드는 빈번한 문맥 교환이 발생하는 시스템에서 성능에 큰 영향을 미칠 수 있습니다.

문맥 교환 비용은 하드웨어 아키텍처에 크게 의존합니다. 예를 들어, x86 아키텍처에서는 많은 레지스터를 저장해야 하고, 메모리 관리 단위(MMU)를 재구성해야 하며, TLB(Translation Lookaside Buffer)와 캐시를 무효화해야 할 수 있습니다. 문맥 교환의 가장 큰 간접적 비용은, 캐시 지역성의 손실로, 새로운 프로세스가 실행을 시작할 때 캐시 미스가 증가하여 성능이 저하됩니다.

현대 운영체제는 다양한 최적화 기법을 도입하여 문맥 교환 오버헤드를 줄이려고 노력합니다. 예를 들어, Linux의 CFS(Completely Fair Scheduler)는 컨텍스트 스위치 빈도와 공정성 사이의 균형을 맞추기 위해 가상 런타임(virtual runtime) 개념을 사용합니다. 또한, 많은 시스템이 프로세서 친화도를 활용하여 프로세스나 스레드가 이전에 실행되었던 CPU에서 계속 실행되도록 하여 캐시 지역성을 유지합니다.

## 문제 11
프로세스와 스레드의 차이점을 자원 공유, 통신 방식, 문맥 교환 비용 측면에서 설명하시오.

**답변:**
프로세스와 스레드의 차이점:

1. 자원 공유 측면:

   프로세스:
   - 독립적인 메모리 주소 공간 보유
   - 다른 프로세스의 변수나 데이터 구조에 직접 접근 불가
   - 파일 디스크립터, 소켓 등은 상속될 수 있으나 기본적으로 독립적
   - 각 프로세스는 자체 PCB(Process Control Block) 보유
   - IPC 메커니즘을 통해 명시적으로 데이터 공유 필요

   스레드:
   - 동일 프로세스 내 스레드들은 주소 공간 공유
   - 코드, 데이터, 힙 영역을 공유하여 직접 접근 가능
   - 파일, 신호, 네트워크 연결 등 프로세스 자원도 공유
   - 각 스레드는 자체 TCB(Thread Control Block) 보유
   - 스택과 레지스터만 독립적으로 유지

2. 통신 방식 측면:

   프로세스 간 통신(IPC):
   - 파이프, 명명된 파이프, 메시지 큐 등 OS 제공 메커니즘 필요
   - 공유 메모리 사용 시 명시적인 설정과 동기화 필요
   - 소켓, 신호 등 복잡한 통신 메커니즘 사용
   - 통신 오버헤드가 상대적으로 큼
   - 데이터 직렬화/역직렬화 과정이 필요할 수 있음

   스레드 간 통신:
   - 공유 변수를 통한 직접 통신 가능
   - 동기화 메커니즘(뮤텍스, 세마포어 등)만 필요
   - 별도의 통신 채널 설정 불필요
   - 통신 오버헤드가 최소화됨
   - 참조로 대형 데이터 구조 공유 가능

3. 문맥 교환 비용 측면:

   프로세스 간 문맥 교환:
   - 전체 주소 공간 전환 필요
   - TLB(Translation Lookaside Buffer) 완전 플러시
   - 캐시 무효화 발생 가능성 높음
   - MMU 재구성 필요
   - 전체 CPU 상태와 PCB 업데이트
   - 평균 수 마이크로초~수십 마이크로초 소요

   스레드 간 문맥 교환:
   - 동일 주소 공간 내에서 전환
   - TLB 플러시 불필요(또는 부분적)
   - 캐시 히트율 상대적으로 유지
   - 주소 변환 구조 재사용
   - 레지스터와 스택 포인터만 주로 변경
   - 평균 수백 나노초~수 마이크로초 소요
   - 일반적으로 프로세스 전환의 1/10 ~ 1/100 비용

**해설:**
프로세스와 스레드는 운영체제의 기본 실행 단위지만, 자원 공유, 통신 방식, 성능 측면에서 중요한 차이점이 있습니다.

자원 공유 측면에서, 프로세스는 독립적인 메모리 공간과 시스템 자원을 가지는 반면, 스레드는 프로세스 내에서 대부분의 자원을 공유합니다. 이러한 차이는 보안과 안정성에 영향을 미칩니다. 프로세스 모델은 높은 격리 수준을 제공하여 한 프로세스의 오류가 다른 프로세스에 영향을 미치지 않습니다. 반면, 스레드 모델은 효율성을 높이지만, 한 스레드의 오류가 전체 프로세스에 영향을 줄 수 있습니다.

통신 측면에서, 스레드 간 통신은 공유 메모리를 통해 직접적이고 효율적으로 이루어질 수 있지만, 적절한 동기화가 필요합니다. 프로세스 간 통신은 더 복잡하고 오버헤드가 크지만, 더 강력한 보안 경계를 제공합니다.

문맥 교환 비용은 시스템 성능에 중요한 영향을 미칩니다. 스레드 간 전환은 주소 공간을 변경할 필요가 없어 훨씬 효율적입니다. 이는 CPU 집약적 병렬 작업이나 많은 I/O 작업이 있는 프로그램에서 특히 중요합니다.

현대 시스템에서는 이러한 차이점을 고려하여 하이브리드 접근 방식을 채택하는 경우가 많습니다. 예를 들어, 웹 서버는 여러 프로세스를 생성하고, 각 프로세스 내에서 다수의 스레드를 실행하여 격리와 효율성의 균형을 맞추기도 합니다.

## 문제 12
프로세스 스케줄링 알고리즘의 성능을 평가하는 기준들을 설명하고, 서로 다른 유형의 시스템(일괄 처리 시스템, 대화형 시스템, 실시간 시스템)에서 어떤 기준이 더 중요한지 설명하시오.

**답변:**
프로세스 스케줄링 알고리즘 성능 평가 기준:

1. CPU 이용률(CPU Utilization):
   - 정의: 전체 시간 중 CPU가 작업을 처리하는 시간의 비율
   - 측정: (CPU 실행 시간 / 전체 시간) × 100%
   - 목표: 최대화 (일반적으로 40% ~ 90%)

2. 처리량(Throughput):
   - 정의: 단위 시간당 완료되는 프로세스의 수
   - 측정: 완료된 작업 수 / 경과 시간
   - 목표: 최대화

3. 반환 시간(Turnaround Time):
   - 정의: 프로세스 제출부터 완료까지 걸리는, 총 시간
   - 측정: 완료 시간 - 도착 시간
   - 목표: 최소화

4. 대기 시간(Waiting Time):
   - 정의: 프로세스가 준비 큐에서 대기하는 총 시간
   - 측정: CPU를 할당받기 위해 대기한 모든 시간의 합
   - 목표: 최소화

5. 응답 시간(Response Time):
   - 정의: 요청 제출부터 첫 응답이 나올 때까지의 시간
   - 측정: 첫 번째 응답 시간 - 요청 시간
   - 목표: 최소화

6. 예측 가능성(Predictability):
   - 정의: 작업 실행 시간의 일관성과 예측 가능 정도
   - 측정: 응답 시간 또는 반환 시간의 표준 편차
   - 목표: 변동성 최소화

7. 공정성(Fairness):
   - 정의: 모든 프로세스가 적절한 CPU 시간을 받는 정도
   - 측정: 프로세스 간 대기 시간 또는 CPU 할당 시간의 편차
   - 목표: 형평성 극대화

다양한 시스템 유형별 중요 기준:

1. 일괄 처리 시스템(Batch Systems):
   - 주요 기준: 처리량, 반환 시간, CPU 이용률
   - 이유:
     * 사용자 상호작용이 없어 응답 시간 중요도 낮음
     * 전체 작업 완료 시간 최소화가 목표
     * 시스템 자원 효율적 활용이 중요

2. 대화형 시스템(Interactive Systems):
   - 주요 기준: 응답 시간, 공정성, 예측 가능성
   - 이유:
     * 사용자 경험에 직접적 영향을 미치는 빠른 응답 필요
     * 모든 사용자에게 공정한 처리 제공 필요
     * 응답 시간의 급격한 변동은 사용자 만족도 저하

3. 실시간 시스템(Real-time Systems):
   - 주요 기준: 데드라인 충족률, 예측 가능성, 최악 경우 실행 시간
   - 이유:
     * 시간 제약 조건 충족이 절대적으로 중요
     * 경성 실시간(hard real-time) 시스템에서 데드라인 미준수는 시스템 실패로 간주
     * 결정적(deterministic) 행동 패턴이 필수적

**해설:**
프로세스 스케줄링 알고리즘의 성능 평가는 시스템의 목적과 환경에 따라 다른 기준을 중요시합니다. 이러한 기준들은 종종 상충 관계(trade-off)를 가지므로, 모든 기준을 동시에 최적화하기는 어렵습니다.

일괄 처리 시스템은 사용자가 직접 대기하지 않으므로 응답성보다는 시스템 전체의 효율성을 중시합니다. 예를 들어, 과학 계산이나 데이터 처리 배치 작업은 CPU 이용률과 처리량을 극대화하는 스케줄링 알고리즘이 적합합니다. FCFS(First-Come, First-Served)나 SJF(Shortest Job First)와 같은 알고리즘이 자주 사용됩니다.

대화형 시스템에서는 사용자 경험이 가장 중요하므로 빠른 응답 시간이 핵심입니다. 사용자는 명령 입력 후 즉각적인 반응을 기대하므로, 라운드 로빈(Round Robin)이나 다단계 피드백 큐(Multilevel Feedback Queue)와 같이 응답성을 높이는 알고리즘이 선호됩니다. 또한, 모든 사용자가 공정하게 대우받는 것도 중요합니다.

실시간 시스템에서는 정확한 타이밍과 예측 가능성이 가장 중요합니다. 특히 경성 실시간 시스템에서는 데드라인을 놓치는 것이 시스템 실패로 간주될 수 있습니다. 따라서 Rate Monotonic이나 Earliest Deadline First와 같이 데드라인을 명시적으로 고려하는 스케줄링 알고리즘이 사용됩니다.

현대 운영체제는 이러한 다양한 요구사항을 충족시키기 위해 복합적인 스케줄링 알고리즘을 채택하거나, 동적으로 알고리즘 매개변수를 조정합니다. 예를 들어, Linux의 CFS(Completely Fair Scheduler)는 처리량, 공정성, 응답성 간의 균형을 맞추기 위해 복잡한 메커니즘을 사용합니다.

## 문제 13
프로세스의 생성과 종료 과정을 UNIX/Linux 시스템을 예로 들어 상세히 설명하시오. 관련 시스템 콜과 자원 할당 및 해제 과정을 포함하시오.

**답변:**
UNIX/Linux 시스템에서의 프로세스 생성 과정:

1. 프로세스 생성 단계:

   a. fork() 시스템 콜:
   - 부모 프로세스가 fork() 호출
   - 커널이 새로운 프로세스 구조체(task_struct) 생성
   - 부모 프로세스의 주소 공간을 복제(Copy-on-Write 기법 활용)
   - 파일 디스크립터, 신호 처리기 등 복제
   - 고유한 PID(Process ID) 할당
   - 부모 프로세스에는 자식 PID 반환, 자식 프로세스에는 0 반환

   b. exec() 계열 시스템 콜(선택적):
   - 자식 프로세스가 exec() 호출하여 새 프로그램 이미지로 대체
   - execve(), execl(), execlp(), execv(), execvp() 등 다양한 변형 존재
   - 호출 프로세스의 주소 공간을 새로운 프로그램으로 덮어씀
   - 새 프로그램의 텍스트, 데이터, BSS, 스택 세그먼트 로드
   - 프로그램 진입점(entry point)에서 실행 시작

   c. 자원 할당:
   - 메모리: 커널 내부 자료구조, 사용자 공간 할당
   - 파일: 파일 테이블 항목 생성 또는 참조 카운트 증가
   - 디렉토리: 작업 디렉토리 정보 복제
   - 시그널: 시그널 처리기 및 마스크 설정

2. 프로세스 실행:
   - 스케줄러에 의해 CPU 할당 받아 실행
   - 시스템 콜을 통한 커널 서비스 요청
   - 인터럽트와 신호 처리

UNIX/Linux 시스템에서의 프로세스 종료 과정:

1. 프로세스 종료 단계:

   a. exit() 시스템 콜:
   - 프로세스가 자발적으로 exit() 호출(또는 main() 함수 반환)
   - 종료 상태(exit status) 지정(0: 정상, 비0: 오류)
   - 비자발적 종료의 경우, 시그널(SIGKILL, SIGSEGV 등)에 의해 발생

   b. 자원 해제:
   - 메모리 자원(스택, 힙, 코드, 데이터 영역) 해제
   - 열린 파일 닫기(파일 디스크립터 테이블 정리)
   - 획득한 락, 세마포어 등 해제
   - 자식 프로세스 처리(INIT 프로세스에 입양 또는 종료)

   c. 좀비(Zombie) 상태:
   - 프로세스 종료 후, 커널은 일부 정보(PID, 종료 상태, 자원 사용 통계)를 유지
   - 이 상태를 "좀비" 또는 "디펙트"(defunct) 상태라고 함
   - 부모 프로세스가 종료 상태를 수집할 때까지 유지

   d. wait() 계열 시스템 콜:
   - 부모 프로세스가 wait(), waitpid(), waitid() 등을 호출하여 자식 종료 상태 수집
   - 좀비 상태 제거 및 남은 자원 완전히 해제
   - 부모가 wait()를 호출하지 않으면 자식은 좀비 상태로 남음

2. 특수 종료 상황:
   - 부모가 자식보다 먼저 종료: 자식 프로세스는 "고아(orphan)"가 되어 init(PID 1)에 입양됨
   - 시그널에 의한 강제 종료: SIGKILL(9) 등의 시그널로 인한 즉시 종료
   - 커널 패닉(panic): 심각한 시스템 오류로 인한 전체 시스템 종료

**해설:**
UNIX/Linux 시스템에서 프로세스 생성은 일반적으로 fork()와 exec() 두 단계로 이루어집니다. 이 모델은 매우 유연하여 다양한 용도로 활용됩니다. fork()만 호출하면 부모와 동일한 프로그램이 실행되며, fork() 후 exec()를 호출하면 새로운 프로그램이 실행됩니다.

fork() 시스템 콜은 현대 구현에서 Copy-on-Write(COW) 기법을 사용하여 최적화됩니다. 실제 메모리 복사는 한쪽이 데이터를 수정할 때까지 지연되어, 불필요한 복사를 방지합니다. 이는 특히 fork() 직후 exec()를 호출하는 일반적인 패턴에서 효율적입니다.

프로세스 종료는 자원 정리와 부모-자식 관계 처리를 포함합니다. 특히 좀비 프로세스 관리는 중요한 이슈입니다. 좀비는 실행을 완료했지만 부모가 종료 상태를 수집하지 않아 시스템 테이블 공간을 계속 차지하는 프로세스입니다. 좀비가 너무 많아지면 시스템 성능이 저하될 수 있습니다.

wait() 계열 시스템 콜은 부모-자식 동기화와 좀비 방지에 중요합니다. 이를 통해 부모는 자식의 종료 상태를 확인하고, 자식 프로세스 정보를 시스템에서 완전히 제거할 수 있습니다. 부모가 자식보다 먼저 종료되는 경우, init 프로세스가 고아 프로세스를 입양하여 정리함으로써 시스템 자원 누수를 방지합니다.

## 문제 14
프로세스 식별자(PID)와 프로세스 그룹의 역할을 설명하고, 프로세스 계층 구조가 UNIX/Linux 시스템에서 어떻게 관리되는지 설명하시오.

**답변:**
프로세스 식별자(PID)의 역할:

1. 개념과 특성:
   - 시스템 내 각 프로세스를 고유하게 식별하는 정수값
   - 프로세스 생성 시 커널이 할당
   - 재사용 가능: 프로세스 종료 후 일정 시간이 지나면 새 프로세스에 할당 가능
   - 일반적으로 순차적으로 할당되나, 특정 PID 범위 내에서 제한됨
   - UNIX/Linux에서 1~32767 또는 그 이상의 범위(커널 설정에 따라 다름)

2. 특수 PID 값:
   - PID 0: 스케줄러/스와퍼(swapper) - 커널 프로세스
   - PID 1: init/systemd - 모든 프로세스의 최상위 조상
   - PID 2: 페이지 데몬(pagedaemon) - 메모리 관리 담당

3. 관련 식별자:
   - PPID(Parent PID): 부모 프로세스의 PID
   - TGID(Thread Group ID): 프로세스의 메인 스레드 PID

프로세스 그룹의 역할:

1. 개념과 구성:
   - 하나 이상의 관련 프로세스로 구성된 컬렉션
   - 각 그룹은 프로세스 그룹 ID(PGID)로 식별
   - 보통 그룹 내 첫 프로세스의 PID가 PGID가 됨
   - setpgid() 시스템 콜로 생성 및 조정

2. 주요 기능:
   - 시그널 전송 단위: 그룹 전체에 동시에 시그널 전송 가능
   - 작업 제어(job control): 셸에서 포그라운드/백그라운드 작업 관리
   - 프로세스 간 관계 구성: 파이프라인 등 관련 프로세스 그룹화

3. 세션(Session):
   - 하나 이상의 프로세스 그룹으로 구성
   - setsid() 시스템 콜로 새 세션 생성
   - 터미널 제어와 연결된 개념
   - 세션 ID는 보통 세션 리더의 PID

UNIX/Linux 시스템의 프로세스 계층 구조 관리:

1. 계층 구조 구성:
   - 트리 형태의 부모-자식 관계로 구성
   - 모든 프로세스는 init/systemd를 루트로 하는 트리의 노드
   - fork() 시스템 콜을 통한 부모-자식 관계 형성
   - 각 프로세스는 하나의 부모와 0개 이상의 자식 가질 수 있음

2. 계층 구조 관리 메커니즘:
   - 태스크 구조체(task_struct): 프로세스 관련 정보 포함
     * 부모 프로세스 포인터
     * 자식 프로세스 리스트
     * 형제 프로세스 리스트
   - 프로세스 테이블: 모든 활성 프로세스 추적
   - /proc 파일 시스템: 프로세스 정보 접근 인터페이스

3. 고아 프로세스 처리:
   - 부모가 wait() 호출 없이 종료되면 자식은 "고아" 상태가 됨
   - init/systemd 프로세스(PID 1)가 자동으로 고아 프로세스의 새 부모가 됨
   - init은 주기적으로 wait() 호출하여 입양한 자식 정리

4. 좀비 프로세스 관리:
   - 종료되었지만 부모가 wait() 호출하지 않은 프로세스
   - 커널은 최소한의 정보만 유지(PID, 종료 상태, 자원 사용 통계)
   - 부모가 wait() 호출하거나 종료되어 init이 입양해 정리할 때까지 유지

5. 프로세스 계층 구조 시각화 및 조회:
   - ps 명령: -f 옵션으로 PPID 등 계층 정보 표시
   - pstree 명령: 프로세스 트리 시각적 표현
   - 사용자 인터페이스: 시스템 모니터링 도구에서 계층 구조 표시

**해설:**
프로세스 식별자(PID)는 프로세스 관리의 기본 요소로, 운영체제가 각 프로세스를 추적하고 제어하는 데 필수적입니다. PID는 프로세스에 관련된 모든 작업(종료, 우선순위 변경, 시그널 전송 등)에서 참조점으로 사용됩니다. Linux에서는 `/proc/{pid}` 디렉토리를 통해 각 프로세스의 다양한 정보에 접근할 수 있습니다.

프로세스 그룹과 세션은 UNIX/Linux 시스템의 작업 제어 메커니즘의 핵심 개념입니다. 이들은 특히 셸 환경에서 중요한 역할을 합니다. 예를 들어, 파이프라인 명령어(예: `ls | grep txt | wc -

