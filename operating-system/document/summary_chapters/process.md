# 프로세스와 스레드 개념 - 헷갈리기 쉬운 문제들

다음은 각 키워드별로 흔히 혼동되는 개념과 OS에서 틀리기 쉬운 문제들입니다:

## 프로세스 개념 기초

**문제 1:** 단일 코어 CPU에서 5개의 프로세스가 동시에 실행되고 있는 것처럼 보입니다. 이것이 가능한 메커니즘을 설명하고, 왜 이것이 진정한 동시 실행이 아닌지 설명하세요.

**해답:** 이것은 시분할(time-sharing) 또는 시간 슬라이싱(time-slicing)으로, CPU가 프로세스 간에 빠르게 전환하여 병렬성의 환상을 만듭니다. 운영체제는 각 프로세스에 작은 시간 양자(time quanta)를 할당합니다. 단일 코어 CPU에서는 한 순간에 실제로 하나의 프로세스만 실행되고 나머지는 준비(ready) 상태에서 차례를 기다립니다. 문맥 전환(context switching)이 매우 빠르게 발생하여 사용자는 여러 프로세스가 동시에 실행되는 것처럼 인식하지만, 실제로는 순차적 실행입니다.[1]

**문제 2:** 프로세스 A가 fork()를 사용하여 자식 프로세스 B를 생성합니다. 프로세스 A가 예기치 않게 종료되면 프로세스 B는 어떻게 되나요?

**해답:** 프로세스 B는 독립적으로 계속 실행됩니다. fork()를 통해 프로세스가 생성되면, 자체 PCB와 리소스를 가진 독립 프로세스가 됩니다. 부모 프로세스가 종료되면 자식은 고아(orphan) 상태가 되고 init 프로세스(PID 1)에 의해 입양되어 새로운 부모가 됩니다. 자식의 실행은 원래 부모의 종료에 영향을 받지 않습니다.[1]

**문제 3:** 성공적인 fork() 호출 후, 부모와 자식 프로세스 간의 관계에 대한 다음 설명 중 틀린 것은?

a) 자식 프로세스는 부모의 파일 디스크립터 복사본을 가진다
b) 자식 프로세스는 fork() 직후 다른 메모리 공간을 가진다
c) 자식 프로세스는 부모의 시그널 핸들러를 상속받는다
d) 자식은 초기에 부모와 물리적 메모리 페이지를 공유한다

**해답:** b)가 틀렸습니다. 자식은 처음에 다른 물리적 메모리를 갖지 않습니다. 현대 운영체제는 fork()를 copy-on-write로 구현하여, 한 프로세스가 페이지를 수정할 때까지 부모와 자식 간에 물리적 메모리 페이지를 공유합니다. 이 최적화는 불필요한 복제를 방지합니다. 자식은 고유한 논리적 주소 공간을 가지지만, 물리적 메모리는 초기에 공유되며 수정 시에만 복사됩니다.[1]

**문제 4:** 프로세스 P1이 다른 프로세스 P2와 통신해야 합니다. 어떤 메커니즘을 통해 각 데이터 액세스마다 커널 개입 없이 직접 메모리를 공유할 수 있나요?

**해답:** 공유 메모리(메모리 매핑/mmap을 통한)는 프로세스가 주소 공간의 일부를 직접 공유할 수 있게 합니다. 공유 메모리가 설정되면 프로세스는 각 액세스마다 커널 개입 없이 이 메모리를 읽고 쓸 수 있습니다. 파이프, 시그널, 메시지 큐와 같은 다른 IPC 메커니즘은 모두 각 데이터 전송마다 시스템 콜이 필요하므로 매번 커널 개입이 필요합니다.[1]

**문제 5:** 한 사용자가 시스템에 수천 개의 좀비 프로세스가 있음에도 정상적으로 작동한다고 보고합니다. 좀비 프로세스가 무엇인지, 왜 누적될 수 있는지, 그리고 시스템이 여전히 기능할 수 있는 이유를 설명하세요.

**해답:** 좀비 프로세스(defunct processes)는 실행을 완료했지만 부모가 wait()/waitpid()를 사용하여 종료 상태를 읽지 않았기 때문에 프로세스 테이블에 여전히 항목이 있는 프로세스입니다. 이들은 부모 프로세스가 종료된 자식을 제대로 정리하지 않을 때 누적됩니다. 좀비는 작은 프로세스 테이블 항목을 제외하고는 CPU나 메모리 리소스를 소비하지 않기 때문에 시스템은 여전히 기능할 수 있습니다. 그러나 충분한 좀비가 누적되면 시스템이 PID를 소진하여 새 프로세스 생성을 방해할 수 있습니다.[1]

## 프로그램 vs 프로세스 구분

**문제 1:** 프로그램과 프로세스의 관계를 올바르게 설명하는 것은?

a) 프로그램은 능동적 개체이고 프로세스는 수동적 개체이다
b) 프로세스는 능동적 개체이고 프로그램은 수동적 개체이다
c) 여러 프로세스가 하나의 프로그램과 연관될 수 있다
d) 프로세스는 수명 동안 하나의 프로그램만 실행할 수 있다

**해답:** b)와 c) 모두 맞습니다. 프로세스는 능동적 개체(프로그램의 실행)이며 프로그램은 수동적 개체(디스크에 저장된 명령어)입니다. 여러 프로세스가 단일 프로그램과 연관될 수 있습니다. 예를 들어, 여러 사용자가 동일한 실행 파일(웹 브라우저 등)을 실행하면 동일한 프로그램 파일에서 여러 개의 고유한 프로세스가 생성됩니다.[1]

**문제 2:** 두 사용자가 동시에 동일한 실행 파일 "/usr/bin/firefox"를 실행합니다. 어떤 진술이 맞나요?

a) 하나의 프로그램과 하나의 프로세스가 있다
b) 하나의 프로그램과 두 개의 프로세스가 있다
c) 두 개의 프로그램과 하나의 프로세스가 있다
d) 두 개의 프로그램과 두 개의 프로세스가 있다

**해답:** b) 하나의 프로그램과 두 개의 프로세스가 있습니다. 실행 파일(/usr/bin/firefox)은 디스크에 저장된 하나의 프로그램이지만, 두 사용자가 실행할 때 각각 자체 메모리 공간, 프로세스 ID 및 실행 상태를 가진 두 개의 별도 프로세스가 생성됩니다.[1]

**문제 3:** 프로세스 P가 프로그램 X를 실행하기 위해 exec() 시스템 호출을 실행합니다. exec() 호출이 성공적으로 완료된 후, 원래 프로세스 P에서 어떤 속성이 보존되나요?

a) 스택 메모리
b) 프로세스 ID
c) 코드(텍스트) 세그먼트
d) 힙 메모리

**해답:** b) 프로세스 ID. 프로세스가 exec()를 실행하면 현재 프로그램(코드, 데이터, 스택, 힙)을 새 프로그램으로 교체하지만 동일한 프로세스 ID를 유지합니다. 일반적으로 열린 파일 디스크립터(close-on-exec으로 표시되지 않은 경우), 프로세스 소유자, 부모 프로세스 ID, 프로세스 그룹, 시그널 핸들러, 리소스 제한도 유지됩니다. 메모리 세그먼트(스택, 힙, 텍스트, 데이터)는 모두 새 프로그램의 세그먼트로 대체됩니다.[1]

**문제 4:** 프로세스의 메모리 크기가 2GB인데 실행 파일은 디스크에서 5MB에 불과합니다. 이 차이의 가장 가능성 높은 이유를 설명하세요.

**해답:** 이 차이는 프로세스가 정적 프로그램 크기와 비교하여 메모리를 할당하고 사용하는 방식 때문입니다. 실행 파일(5MB)에는 코드와 초기화된 데이터만 포함되지만, 실행 중인 프로세스의 메모리에는 다음이 포함됩니다:
1. 런타임에 할당된 힙 메모리(malloc/new를 통해)
2. 함수 호출 및 지역 변수를 위한 스택 공간
3. 로드된 공유 라이브러리
4. 메모리 매핑된 파일
5. 전체 가상 주소 공간(드문드문 채워짐)
6. 실행 중에 커지는 데이터 구조

프로세스가 상당한 힙 메모리를 할당했거나 실행 중에 큰 파일을 매핑했을 수 있어, 원래 실행 파일보다 메모리 사용량이 훨씬 많아집니다.[1]

**문제 5:** 리눅스 시스템에서 실행 파일과 프로세스의 주요 차이점은 무엇인가요?

**해답:** 실행 파일은 디스크에 저장된 정적 바이너리 파일로 명령어와 데이터를 포함하는 반면, 프로세스는 자체 상태를 가진 해당 프로그램의 동적 실행입니다. 구체적으로:
- 실행 파일은 수동적이고 파일시스템에 저장되며 프로그램 코드와 정적 데이터를 포함합니다.
- 프로세스는 능동적이며 프로세스 ID를 가지고, 실행 상태(스택, 레지스터, 프로그램 카운터)를 포함하며, 할당된 리소스(메모리, 파일 핸들)가 있고, 다른 프로세스와 통신할 수 있으며, OS 스케줄러에 의해 관리됩니다.
- 동일한 실행 파일에서 각각 자체 상태를 가진 여러 프로세스가 동시에 실행될 수 있습니다.[1]

## 프로세스 메모리 레이아웃

**문제 1:** 스택의 배열 끝을 넘어 쓰기를 허용하는 버퍼 오버플로우 취약점이 있을 경우, 어떤 것이 손상될 가능성이 가장 높나요?

a) 힙 데이터
b) 현재 함수의 리턴 주소
c) 데이터 세그먼트의 전역 변수
d) 텍스트 세그먼트의 프로그램 기계어 코드

**해답:** b) 현재 함수의 리턴 주소. 대부분의 아키텍처에서 스택 메모리는 아래쪽으로 성장하며, 현재 함수 호출의 리턴 주소는 지역 변수 근처의 스택에 저장됩니다. 스택의 버퍼(배열)가 오버플로우되면 스택의 인접한 메모리 위치를 덮어쓰게 되는데, 이에는 저장된 리턴 주소가 포함될 수 있습니다. 이것이 많은 스택 기반 버퍼 오버플로우 공격의 기초입니다.[1]

**문제 2:** 다음 C 코드를 실행하면 어떤 메모리 영역이 커지고, 어떤 잠재적 문제가 발생할 수 있나요?
```c
void recursive_function() {
    int large_array[10000];
    recursive_function();  // 종료 조건 없이 자신을 호출
}
```

**해답:** 스택 메모리 영역이 각 재귀 호출마다 커지게 됩니다. 각 호출은 large_array와 함수 메타데이터를 위한 공간을 할당해야 하기 때문입니다. 잠재적 문제는 스택 오버플로우입니다. 각 재귀 호출은 (4바이트 정수를 가정하면) 40KB와 함수 호출 오버헤드를 소비하므로, 종료 조건이 없어 스택은 빠르게 가용 공간을 소진하게 됩니다. 이로 인해 스택 오버플로우 오류가 발생하고 세그멘테이션 폴트로 프로그램이 종료됩니다.[1]

**문제 3:** 프로세스가 malloc()을 호출하여 메모리를 할당한 다음 fork()를 호출하고, 자식 프로세스가 해당 메모리를 해제합니다. 부모 프로세스에서 해당 메모리는 어떻게 되나요?

**해답:** 메모리는 부모 프로세스에서 여전히 할당된 상태로 유지됩니다. fork()가 호출되면 자식은 힙 할당을 포함한 부모 메모리의 복사본을 받지만, 각 프로세스는 fork 이후에 자체 별도 주소 공간을 갖습니다. 자식이 할당된 메모리의 복사본을 해제해도 부모의 메모리에는 영향이 없습니다. 부모는 메모리 누수를 방지하기 위해 여전히 자체 할당을 해제해야 합니다.[1]

**문제 4:** 프로그래머가 이 C 코드에서 "Hello" 문자열을 수정하려고 합니다:
```c
char *str = "Hello";
str[0] = 'J';  // "Hello"를 "Jello"로 변경 시도
```
프로그램이 세그멘테이션 폴트로 충돌합니다. 이유와 해결 방법을 설명하세요.

**해답:** 프로그램이 충돌하는 이유는 C에서 문자열 리터럴이 읽기 전용 데이터 섹션(텍스트 세그먼트의 일부)에 저장되어 쓰기가 불가능하기 때문입니다. 코드가 문자열 리터럴을 수정하려고 할 때 메모리 보호 위반이 발생합니다.

해결하려면 프로그래머는 수정 가능한 문자열 복사본을 만들어야 합니다:
```c
char str[] = "Hello";  // 스택에 수정 가능한 복사본 생성
str[0] = 'J';          // 정상 작동
```

또는 힙 메모리 사용:
```c
char *str = strdup("Hello");  // 힙에 수정 가능한 복사본 생성
str[0] = 'J';                 // 정상 작동
free(str);                    // 메모리 해제
```

두 솔루션 모두 읽기 전용 원본을 수정하려는 대신 스택이나 힙에 쓰기 가능한 복사본을 만듭니다.[1]

**문제 5:** 대량의 데이터를 처리하는 장기 실행 애플리케이션에서 일반적으로 가장 큰 메모리 섹션은 무엇인가요?

**해답:** 힙은 일반적으로 데이터를 처리하는 장기 실행 애플리케이션에서 가장 큰 섹션입니다. 힙은 동적 메모리 할당(malloc(), new 등을 통해)이 발생하는 곳이며, 데이터 집약적 애플리케이션은 종종 데이터 구조를 저장하고 처리하기 위해 대량의 메모리를 할당합니다. 함수 호출 프레임과 지역 변수에 사용되는 스택(크기가 제한됨)과 달리, 힙은 훨씬 더 크게 성장할 수 있으며 주로 사용 가능한 시스템 메모리와 주소 공간에 의해서만 제한됩니다.[1]

## 프로세스 상태

**문제 1:** 프로세스가 현재 "대기(Waiting)" 상태에 있습니다. 어떤 작업이 이를 "준비(Ready)" 상태로 이동시키지 않나요?

a) 대기 중이던 I/O 작업 완료
b) CPU 스케줄러가 실행을 위해 선택
c) 대기 중이던 세마포어 사용 가능
d) 대기 중이던 타이머 만료

**해답:** b) CPU 스케줄러가 실행을 위해 선택. 이것은 프로세스를 "준비(Ready)" 상태에서 "실행(Running)" 상태로 이동시키며, "대기(Waiting)"에서 "준비(Ready)"로 이동시키지 않습니다. "대기" 상태의 프로세스는 대기 중이던 이벤트(I/O 완료, 세마포어 가용성, 타이머 만료)가 발생하면 "준비" 상태로 이동하여 스케줄링 대상이 됩니다.[1]

**문제 2:** 단일 CPU 시스템에서 한 번에 "실행(Running)" 상태에 있을 수 있는 프로세스는 몇 개인가요? 실행 준비가 된 다른 프로세스는 어떻게 되나요?

**해답:** 단일 CPU에서는 한 번에 오직 하나의 프로세스만 "실행(Running)" 상태일 수 있습니다. 실행 준비가 된 다른 프로세스는 "준비(Ready)" 상태로, 준비 큐에서 대기합니다. CPU 스케줄러는 사용 중인 스케줄링 알고리즘에 따라 다음에 실행할 준비된 프로세스를 결정합니다. 컨텍스트 스위치가 발생하면 실행 중인 프로세스는 "준비" 또는 "대기" 상태로 이동하고, 준비 큐에서 프로세스가 선택되어 실행됩니다.[1]

**문제 3:** 프로세스가 "종료(Terminated)" 상태이지만 여전히 프로세스 테이블에 나타납니다. 이 상황에 대한 가장 가능성 높은 설명은 무엇인가요?

**해답:** 프로세스가 실행을 완료했지만 부모가 아직 wait() 또는 waitpid()를 호출하여 종료 상태를 수집하지 않았습니다. 이런 프로세스를 "좀비(zombie)" 프로세스라고 합니다. 프로세스 테이블의 항목을 제외한 모든 리소스를 해제했지만, 부모 프로세스가 종료를 확인할 때까지 이 항목은 유지됩니다. 부모가 wait()를 호출하지 않으면 부모가 종료될 때까지 좀비가 지속되며, 그 후 init 프로세스(PID 1)가 좀비를 입양하여 정리합니다.[1]

**문제 4:** 프로세스가 네트워크 소켓에서 읽기 위해 블로킹 시스템 콜을 수행합니다. 호출 전부터 데이터가 수신되고 처리될 때까지의 전체 상태 전환 순서를 추적하세요.

**해답:** 상태 전환 순서는 다음과 같습니다:
1. 실행 → 대기: 프로세스가 블로킹 읽기 시스템 콜을 만들고 데이터가 즉시 사용 가능하지 않으면, 소켓에 데이터가 도착하기를 기다리며 "실행"에서 "대기"로 전환됩니다.
2. 대기 → 준비: 네트워크 데이터가 도착하면 네트워크 인터럽트 핸들러가 읽기 작업을 완료하고 프로세스를 "대기"에서 "준비"로 이동시킵니다.
3. 준비 → 실행: CPU 스케줄러가 이 프로세스를 선택하면 "준비"에서 "실행"으로 전환됩니다.
4. 그런 다음 프로세스는 계속 실행되어 수신된 데이터를 처리합니다.
5. 실행 → 준비: 프로세스의 시간 양자가 만료되면 "준비" 상태로 돌아가 다음 차례를 기다릴 수 있습니다.[1]

**문제 5:** 프로세스가 fork()를 사용하여 생성되었지만 시스템 부하가 낮음에도 불구하고 "실행(Running)" 상태에 도달하지 않습니다. 이런 동작의 가능한 이유는 무엇인가요?

**해답:** 가능한 이유는 다음과 같습니다:
1. 부모 프로세스의 우선순위가 더 높고, 스케줄링 알고리즘이 우선순위 기반인 경우
2. 자식 프로세스가 리소스에 즉시 차단되었을 수 있음("대기" 상태 진입)
3. 부모가 스케줄링되기 전에 kill()을 사용하여 자식을 종료했을 수 있음
4. 자식이 초기화되는 것을 방지하는 리소스 제한이 있을 수 있음
5. 프로세스가 일시 중단 상태로 생성되어 명시적으로 재개해야 할 수 있음
6. 자식이 다른 프로세스가 보유한 리소스를 기다리는 데드락 상황[1]

## 프로세스 제어 블록(PCB) 구성 요소

**문제 1:** 컨텍스트 스위치가 발생할 때 저장 및 복원할 필요가 없는 PCB 구성 요소는?

a) CPU 레지스터
b) 프로그램 카운터
c) 프로세스 우선순위
d) 메모리 관리 정보
e) 프로세스 상태

**해답:** c) 프로세스 우선순위. 컨텍스트 스위치 동안 CPU 상태(레지스터, 프로그램 카운터)와 메모리 관리 정보는 나가는 프로세스에 대해 저장되고 들어오는 프로세스에 대해 복원되어야 합니다. 우선순위와 같은 프로세스 속성은 PCB에 남아 있으며 컨텍스트 스위치 중에 변경되지 않습니다. 이들은 각 스위치마다 저장/복원이 필요한 실행 상태가 아니라 프로세스의 지속적인 속성입니다.[1]

**문제 2:** PCB에는 다른 PCB를 가리키는 포인터가 포함되어 있습니다. 이 포인터들은 어떤 관계를 나타내며 왜 필요한가요?

**해답:** 이 포인터들은 프로세스 관계와 조직 구조를 나타냅니다:
1. 부모-자식 관계(부모 포인터, 자식 목록)
2. 형제 관계(같은 부모를 가진 프로세스)
3. 프로세스 그룹 및 세션 관계
4. 스케줄러 큐를 위한 다음/이전 프로세스 포인터

이 포인터들이 OS에 필요한 이유:
- 프로세스 계층 구조 관리
- 작업 제어 구현
- 프로세스 종료 처리(자식이 종료되면 부모에게 알림)
- 스케줄링을 위한 프로세스 효율적 조직
- 프로세스 트리 및 커널이 사용하는 다양한 연결 리스트 구축[1]

**문제 3:** 프로세스의 PCB 내용이 실수로 손상된 경우, 가장 가능성 높은 결과는?

a) 프로세스가 즉시 충돌한다
b) 프로세스가 계속 실행되지만 잘못된 결과를 생성한다
c) 운영체제가 프로세스를 제대로 관리할 수 없게 된다
d) 시스템의 다른 프로세스도 손상된다

**해답:** c) 운영체제가 프로세스를 제대로 관리할 수 없게 됩니다. PCB에는 OS가 프로세스를 관리하는 데 필요한 상태, 레지스터 값, 메모리 매핑, 스케줄링 정보와 같은 중요한 정보가 포함되어 있습니다. 이 정보가 손상되면 OS는 프로세스를 올바르게 스케줄링하거나, 메모리를 관리하거나, 시스템 호출을 처리할 수 없습니다. 이로 인해 프로세스가 올바르게 또는 전혀 실행되지 못하고, OS는 일관성 없는 상태로 인해 결국 프로세스를 종료할 수 있습니다.[1]

**문제 4:** 다중 사용자 시스템에서 서로 다른 우선순위를 가진 사용자 간에 공정한 리소스 할당을 보장하는 데 가장 중요한 PCB 구성 요소는 무엇인가요?

**해답:** PCB의 스케줄링 정보 구성 요소가 가장 중요하며, 다음을 포함합니다:
1. 프로세스 우선순위(관리자가 할당한 정적 우선순위와 스케줄러가 조정한 동적 우선순위 모두)
2. 누적 CPU 사용 시간
3. 시간 양자 값
4. 계정 및 우선순위 계산을 위한 사용자/그룹 ID 정보

스케줄러는 이 정보를 사용하여 다음에 실행할 프로세스를 결정하고, 우선순위가 높은 사용자가 적절한 CPU 시간을 받으면서 우선순위가 낮은 프로세스가 기아 상태가 되지 않도록 합니다. 계정 정보를 통해 시스템은 사용자별 사용량을 추적하고 그에 따라 우선순위를 조정할 수 있습니다.[1]

**문제 5:** PCB의 어떤 정보가 다중프로세서 시스템에서 프로세스를 다른 CPU 코어로 이동할 수 있게 하나요?

**해답:** PCB에는 프로세스가 CPU 코어 간에 이동할 수 있게 하는 몇 가지 요소가 포함되어 있습니다:
1. 프로세스의 완전한 레지스터 세트(모든 코어에서 상태를 복원할 수 있음)
2. 프로세스의 주소 공간을 정의하는 메모리 관리 정보(페이지 테이블 등)
3. CPU 친화도 정보(프로세스가 실행 가능한 코어)
4. CPU 상태 정보(부동 소수점 레지스터, 벡터 레지스터 등)
5. 모든 사용 가능한 CPU에 로드할 수 있는 실행 컨텍스트

이 정보를 통해 스케줄러는 한 CPU에서 프로세스의 완전한 상태를 저장하고 다른 CPU에서 복원할 수 있어, 실행 정확성을 유지하면서 여러 코어에 걸쳐 부하 균형을 가능하게 합니다.[1]

## 프로그램 카운터 및 CPU 레지스터

**문제 1:** 시스템 호출 동안 프로세스의 프로그램 카운터는 다음을 가리킵니다:

a) 프로세스 메인 함수의 첫 번째 명령어
b) 프로세스 코드 세그먼트의 주소
c) 커널 코드의 주소
d) 프로세스 주소 공간의 시스템 호출 핸들러

**해답:** c) 커널 코드의 주소. 프로세스가 시스템 호출을 할 때 CPU는 사용자 모드에서 커널 모드로 전환되고, 프로그램 카운터는 커널 주소 공간의 코드, 특히 시스템 호출 핸들러 코드를 실행하기 시작합니다. 프로세스의 사용자 모드 컨텍스트(호출 시점의 프로그램 카운터 값 포함)는 사용자 모드로 돌아갈 때 복원할 수 있도록 저장됩니다.[1]

**문제 2:** 프로세스가 하드웨어 타이머 인터럽트에 의해 중단됩니다. CPU가 인터럽트 처리 후 어떤 명령어를 실행할지 단계별로 설명하세요.

**해답:** 하드웨어 인터럽트가 발생할 때:
1. CPU는 자동으로 현재 프로그램 카운터와 CPU 상태를 커널 스택에 저장합니다.
2. CPU는 인터럽트 벡터 테이블에서 인터럽트 핸들러 루틴 주소로 점프합니다.
3. 인터럽트 핸들러는 필요한 경우 추가 상태를 저장하고 타이머 이벤트를 처리합니다.
4. 핸들러가 완료되면 인터럽트에서 반환하는 명령을 실행합니다.
5. 이 명령은 스택에서 저장된 프로그램 카운터와 CPU 상태를 복원합니다.
6. 그런 다음 CPU는 저장된 주소에서 실행을 계속합니다 - 인터럽트가 발생하지 않았다면 실행되었을 정확한 명령어에서부터 시작합니다.

이 메커니즘은 중단된 프로세스가 중단된 적이 없다는 인식 없이 정확히 중단된 지점에서 계속할 수 있도록 보장합니다.[1]

**문제 3:** 프로세스 A가 실행 중일 때 프로세스 B로 컨텍스트 전환이 발생합니다. 나중에 프로세스 A가 높은 우선순위 신호를 받습니다. 다음에 예약될 때 프로세스 A의 프로그램 카운터는 어떻게 업데이트되나요?

**해답:** 실행 중이 아닐 때 프로세스 A가 높은 우선순위 신호를 받으면:
1. 신호가 프로세스 A의 PCB에 대기 중으로 표시됩니다.
2. 프로세스 A가 다음에 예약될 때, 정상 실행이 재개되기 전에 커널이 대기 중인 신호를 확인합니다.
3. 신호에 핸들러가 있으면 커널은:
   - 현재 프로그램 카운터 값(프로세스 A가 중단된 명령어)을 저장합니다.
   - 프로세스의 저장된 프로그램 카운터를 시그널 핸들러 함수를 가리키도록 수정합니다.
   - 핸들러 이후 정상 실행을 재개하기 위한 리턴 주소를 포함하도록 스택을 설정합니다.
4. 프로세스 A가 실행되면 스위치아웃되었을 때가 아닌 시그널 핸들러에서 실행을 시작합니다.
5. 핸들러가 완료되면 실행은 원래 중단된 지점으로 돌아갑니다.[1]

**문제 4:** 운영체제를 개발할 때 인터럽트 핸들러 내부에서 레지스터 사용에 주의해야 하는 이유는 무엇인가요?

**해답:** 인터럽트 핸들러를 개발할 때 레지스터 사용에 주의해야 하는 이유:
1. 레지스터에는 중단된 프로세스의 상태가 포함되어 있으며 부주의하게 수정하면 해당 상태가 손상됩니다.
2. 인터럽트 핸들러는 비동기적으로 실행되어 다른 핸들러를 포함한 모든 코드를 잠재적으로 중단할 수 있습니다.
3. 핸들러가 저장/복원 없이 레지스터를 수정하면 중단된 코드는 잘못된 레지스터 값으로 재개됩니다.
4. 중첩된 인터럽트(인터럽트 핸들러가 다른 고우선순위 인터럽트에 의해 중단됨)는 여러 레벨에 걸쳐 레지스터 상태를 보존해야 합니다.

제대로 된 핸들러는 진입 시 수정하는 모든 레지스터를 저장하고 반환하기 전에 복원해야 합니다. 그렇지 않으면 인터럽트가 발생한 후 프로세스가 예기치 않게 레지스터 값이 변경되어 시스템이 빠르게 불안정해질 수 있습니다.[1]

**문제 5:** 사용자 프로세스 간 컨텍스트 전환 중에 일부 CPU 레지스터가 저장되지 않는 이유는 무엇인가요?

**해답:** 일부 CPU 레지스터가 컨텍스트 전환 중에 저장되지 않는 이유:
1. CPU 모드나 메모리 관리를 관리하는 제어 레지스터는 커널에 의해 별도로 처리됩니다.
2. 일부 레지스터는 권한 수준 변경 중에 하드웨어에 의해 자동으로 저장/복원됩니다.
3. 디버그 레지스터나 성능 카운터는 커널에 의해 전역적으로 관리될 수 있습니다.
4. 일부 특수 레지스터(특정 SIMD 또는 벡터 레지스터)는 필요할 때만 느리게 저장될 수 있습니다.
5. 커널 사용에 전용된 레지스터는 사용자 프로세스 컨텍스트의 일부가 아닙니다.

사용자 표시 프로세스 상태의 일부를 형성하는 레지스터만 저장/복원이 필요합니다. 프로세스 데이터가 아닌 CPU 동작을 제어하는 시스템 수준 레지스터는 커널에 의해 별도로 관리되며 각 프로세스가 스케줄링될 때 특별히 설정될 수 있습니다.[1]

## 메모리 섹션

**문제 1:** 다음 C 코드를 고려하세요:
```c
#include 

int global = 42;
static int file_static;
const int readonly = 100;

int main() {
    static int func_static = 10;
    int local = 5;
    char *ptr = malloc(1024);
    
    // 코드 여기
    
    free(ptr);
    return 0;
}
```

각 변수를 해당 메모리 섹션과 맞추고 `readonly`가 일부 시스템에서 다르게 동작하는 이유를 설명하세요.

**해답:**
- `global` - 데이터 세그먼트(초기화된 전역)
- `file_static` - BSS 세그먼트(초기화되지 않은 정적)
- `readonly` - 읽기 전용 데이터 섹션(또는 텍스트 세그먼트)
- `func_static` - 데이터 세그먼트(초기화된 정적)
- `local` - 스택
- `ptr`(포인터 자체) - 스택
- `malloc`으로 할당된 메모리 - 힙

`readonly` 변수는 일부 시스템에서는 메모리 보호 및 프로세스 간 공유를 위해 텍스트 세그먼트에 배치될 수 있습니다. 다른 시스템에서는 데이터 세그먼트의 읽기 전용 부분에 배치될 수 있습니다. 이 차이는 코드와 물리적 메모리 페이지를 공유하는지 아니면 다른 읽기 전용 데이터와 공유하는지에 영향을 미칩니다.[1]

**문제 2:** 멀티스레드 프로세스에서 모든 스레드 간에 공유되는 메모리 섹션과 스레드별 메모리 섹션은 무엇인가요?

**해답:**
모든 스레드 간에 공유되는 섹션:
- 텍스트 세그먼트(코드)
- 데이터 세그먼트(초기화된 전역 및 정적 변수)
- BSS 세그먼트(초기화되지 않은 전역 및 정적 변수)
- 힙(동적으로 할당된 메모리)

스레드별 섹션:
- 스택(각 스레드는 자체 사설 스택 보유)
- 스레드 로컬 스토리지(TLS, 스레드별 변수용)

이 공유 모델은 스레드가 "경량"으로 간주되는 이유입니다. 대부분의 메모리 공간을 공유하여 효율적인 통신을 가능하게 하면서 공유 데이터 액세스에 대한 신중한 동기화가 필요합니다.[2]

**문제 3:** 시스템이 아래로 성장하는 스택과 위로 성장하는 힙을 사용하는 경우, 깊은 재귀와 많은 할당이 있는 프로그램이 오랫동안 실행되면 어떻게 되나요?

**해답:** 이러한 시스템에서는 스택-힙 충돌 위험이 있습니다:
1. 깊은 재귀로 인해 스택이 아래로 성장하여 더 많은 메모리를 소비합니다.
2. 수많은 동적 할당으로 인해 힙이 위로 성장합니다.
3. 결국 동일한 메모리 영역을 사용하려고 시도할 수 있습니다.

이 경우:
- 세그먼트 간에 고정 경계가 있으면 스택 오버플로우가 발생할 수 있습니다.
- 충돌을 감지하면 힙 할당이 실패할 수 있습니다.
- 적절한 검사 없이 최악의 경우 하나가 다른 하나의 데이터를 덮어쓸 수 있습니다.

현대 시스템은 일반적으로 스택과 힙 사이에 "가드 영역"(매핑되지 않은 메모리)을 두어 메모리 손상이 발생하기 전에 이러한 충돌을 감지합니다. 감지되면 OS는 메모리 손상을 허용하는 대신 일반적으로 세그멘테이션 폴트로 프로세스를 종료합니다.[1]

**문제 4:** fork()를 사용하여 자식 프로세스를 생성할 때 각 메모리 섹션은 어떻게 되나요?

**해답:** fork()가 자식 프로세스를 생성할 때:

1. 텍스트 세그먼트(코드): 일반적으로 부모와 자식 간에 효율성을 위해 읽기 전용으로 공유됩니다.
2. 데이터 세그먼트: 논리적으로 자식에게 복사되지만 일반적으로 copy-on-write로 구현됩니다 - 물리적 페이지는 수정될 때까지 공유됩니다.
3. BSS 세그먼트: copy-on-write 의미론으로도 복사됩니다.
4. 스택: 자식에게 복사됩니다(copy-on-write), 그러나 각 프로세스는 자체 스택을 가지며 이는 달라집니다.
5. 힙: 자식에게 동일한 할당으로 복사됩니다(copy-on-write), 그러나 향후 malloc/free 작업은 해당 작업을 수행하는 프로세스에만 영향을 미칩니다.

copy-on-write 메커니즘은 한 프로세스가 페이지를 수정할 때까지 물리적 메모리가 실제로 복제되지 않음을 의미하므로, fork()는 전체 메모리 복사보다 훨씬 효율적입니다.[1]

**문제 5:** 포인터가 유효해 보이는데도 다음 코드가 세그멘테이션 폴트를 일으키는 이유는 무엇인가요?
```c
int main() {
    int *ptr = (int*)0x12345678;
    *ptr = 100;  // 세그멘테이션 폴트
    return 0;
}
```

**해답:** 이 코드는 비-NULL 포인터를 가지는 것이 그것이 프로세스의 주소 공간에 유효한 메모리를 가리킨다는 것을 의미하지 않기 때문에 세그멘테이션 폴트를 일으킵니다. 주소 0x12345678:

1. OS가 이 프로세스에 할당한 메모리 세그먼트의 일부가 아닙니다.
2. 메모리 관리 장치(MMU)는 이 가상 주소가 이 프로세스에 할당된 물리적 메모리에 매핑되지 않는다는 것을 감지합니다.
3. 프로그램이 이 주소에 쓰려고 할 때 MMU는 하드웨어 예외를 트리거합니다.
4. OS는 이것을 세그멘테이션 폴트 신호(SIGSEGV)로 변환합니다.

유효한 포인터는 스택, 전역 변수 또는 명시적 할당(malloc)과 같은 메커니즘을 통해 프로세스에 적절하게 할당된 메모리를 가리켜야 합니다. 이와 같은 임의 주소는 거의 확실히 프로세스의 유효한 주소 공간 외부에 있습니다.[1]

## 프로세스 스케줄링 개념

**문제 1:** CPU 스케줄링 알고리즘이 다음과 같은 특성을 가집니다:
- 프로세스가 CPU에 할당되면 I/O를 위해 블록될 때까지 실행됩니다.
- 프로세스는 도착 순서대로 예약됩니다.

이것은 어떤 종류의 스케줄링 알고리즘이며, I/O 중심과 CPU 중심 프로세스가 혼합된 시스템에 어떤 영향을 미칠까요?

**해답:** 이것은 비선점형(non-preemptive) 선입선출(FCFS) 스케줄링 알고리즘입니다. 혼합 워크로드가 있는 시스템에서:

1. I/O 중심 프로세스의 응답 시간이 나쁨: 짧고 대화형 I/O 중심 프로세스가 긴 CPU 중심 프로세스 뒤에서 기다릴 수 있습니다.
2. 호송 효과(convoy effect): 짧은 프로세스가 긴 프로세스 뒤에 갇힙니다.
3. I/O 장치 활용도 낮음: CPU 중심 프로세스가 실행되는 동안 I/O 장치가 유휴 상태가 됩니다.
4. 전체 처리량 저하: 시스템이 단위 시간당 완료하는 프로세스 수가 더 적습니다.
5. 불균형한 리소스 사용: CPU 활용도는 높을 수 있지만 다른 시스템 리소스는 활용도가 낮습니다.

시스템은 사용자에게 응답성이 떨어지게 느껴질 것입니다. 대화형 프로세스(자주 I/O를 기다림)가 CPU 집약적인 작업 뒤에 갇혀 있을 때 불이익을 받기 때문입니다.[1]

**문제 2:** 실시간 운영체제에서 가장 중요한 스케줄링 속성은 무엇인가요?
a) 프로세스 간 공정성
b) CPU 활용도 최대화
c) 타이밍 데드라인 충족
d) 처리량 최대화

**해답:** c) 타이밍 데드라인 충족. 실시간 운영체제는 다른 메트릭보다 결정적 동작과 보장된 응답 시간을 우선시합니다. 실시간 시스템에서 프로세스는 종종 완료해야 하는 데드라인을 가집니다(기계 제어 또는 센서 응답과 같은). 이러한 데드라인을 놓치면 심각한 결과가 발생할 수 있습니다. 실시간 스케줄러는 전체 처리량이나 CPU 활용도가 감소하더라도 우선순위가 높은 작업이 타이밍 제약 내에서 실행되도록 보장합니다.[1]

**문제 3:** 시스템이 동일한 우선순위 프로세스를 위한 라운드 로빈과 함께 우선순위 스케줄링을 사용합니다. 어떤 문제가 발생할 수 있으며, 어떤 메커니즘이 이를 해결하나요?

**해답:** 문제는 우선순위 반전 또는 우선순위가 낮은 프로세스의 기아 상태입니다. 우선순위가 높은 프로세스가 지속적으로 실행 준비가 되어 있다면, 우선순위가 낮은 프로세스는 CPU 시간을 전혀 받지 못할 수 있습니다.

이를 해결하는 메커니즘:
1. **에이징(Aging)**: 오랫동안 기다린 프로세스의 우선순위를 점진적으로 증가
2. **우선순위 상속(Priority inheritance)**: 우선순위가 낮은 프로세스가 우선순위가 높은 프로세스가 필요로 하는 리소스를 보유할 때, 일시적으로 우선순위가 낮은 프로세스의 우선순위를 높임
3. **동적 우선순위 조정**: CPU 사용 기록 및 I/O 행동에 기반하여 우선순위 수정
4. **혼합 스케줄링**: 우선순위가 낮은 프로세스도 주기적으로 CPU 시간을 받도록 보장

이러한 메커니즘은 모든 프로세스가 진행되도록 도와, 우선순위가 낮은 작업의 무기한 연기를 방지합니다.[1]

**문제 4:** 다중 프로세서 시스템에서 프로세스가 CPU1에서 실행되었지만 차단된 후 다시 준비 상태가 되었을 때 CPU2에서 예약됩니다. 이로 인해 어떤 성능 문제가 발생할 수 있나요?

**해답:** 이로 인해 CPU 캐시 친화성 손실이 발생합니다. 현대 CPU에는 최근에 액세스한 데이터와 명령어를 저장하는 다단계 캐시가 있습니다. 프로세스가 CPU1에서 실행될 때 해당 CPU에 특화된 캐시 상태를 구축합니다. 프로세스를 CPU2로 이동하면 모든 캐시된 데이터가 손실되어:

1. 작업 세트가 CPU2의 캐시로 다시 로드되어야 하므로 캐시 미스 발생
2. 캐시가 다시 채워지는 동안 메모리 지연 시간 증가
3. 작업 세트가 재구축될 때까지 성능 저하
4. 전체 시스템 성능에 영향을 미치는 메모리 버스 트래픽 증가 가능성

이것이 현대 스케줄러가 프로세서 친화성을 구현하여 캐시된 데이터를 활용하기 위해 프로세스를 이전에 실행했던 동일한 CPU에 재스케줄링하려고 시도하는 이유입니다. 큰 작업 세트가 있는 프로세스의 경우, 캐시 친화성 손실의 성능 영향이 상당할 수 있습니다.[1]

**문제 5:** 시분할 시스템에서 CPU 중심 프로세스는 종종 자동으로 우선순위가 감소합니다. 이 정책의 근거는 무엇인가요?

**해답:** CPU 집약적 프로세스의 우선순위를 낮추는 근거:
1. **대화형 응답 개선**: I/O 중심 및 대화형 프로세스를 선호하여 시스템이 사용자에게 응답성 있게 느껴지도록 함
2. **공정성**: CPU 중심 프로세스가 다른 프로세스를 희생시키면서 프로세서를 독점하는 것을 방지
3. **균형**: 다양한 워크로드 유형 간에 자연적인 균형 생성
4. **리소스 활용**: CPU뿐만 아니라 모든 시스템 리소스의 효율적인 사용 장려
5. **사용자 경험**: 대화형 애플리케이션은 응답성을 유지하며, 이는 일반적으로 사용자 만족도에 더 중요함

이 정책은 시분할 시스템에서 인식된 성능(응답성)이 종종 원시 처리량보다 더 중요하다는 것을 인정합니다. 그러나 과학 컴퓨팅, 비디오 렌더링 또는 기계 학습 작업과 같은 CPU 집약적 워크로드는 성능이 저하됩니다.[1]

## 단일 스레드 vs 다중 스레드 프로세스

**문제 1:** 다중 스레드 프로세스에서 스레드 A가 I/O 작업에 차단되어 있습니다. 어떤 진술이 맞나요?
a) I/O 작업이 완료될 때까지 전체 프로세스가 차단됩니다.
b) 스레드 A만 차단되고 다른 스레드는 계속 실행됩니다.
c) 스레드 A는 I/O를 기다리는 동안 CPU 주기를 소비합니다.
d) I/O가 너무 오래 걸리면 OS가 스레드 A를 종료합니다.

**해답:** b) 스레드 A만 차단되고 다른 스레드는 계속 실행됩니다. 이것은 다중 스레드 프로그래밍의 주요 이점 중 하나입니다. 스레드가 I/O에서 차단되면 해당 특정 스레드만 대기 상태로 이동하고, 동일한 프로세스의 다른 스레드는 계속 실행될 수 있습니다. 이를 통해 프로세스는 느린 작업을 기다리는 동안 다른 작업을 진행할 수 있어 전체 프로세스 처리량과 응답성이 향상됩니다.[2]

**문제 2:** 다음 두 웹 서버 설계를 비교하세요:
1. 클라이언트당 하나의 스레드가 있는 다중 스레드 서버
2. 논블로킹 I/O와 이벤트 루프를 사용하는 단일 스레드 서버

어떤 시나리오에서 단일 스레드 접근 방식이 더 좋은 성능을 보일까요?

**해답:** 단일 스레드 이벤트 기반 접근 방식은 연결당 활동이 적은 많은 동시 연결을 처리할 때(웹소켓, 채팅 서버 또는 모니터링 연결과 같은) 다중 스레드 접근 방식보다 성능이 좋을 것입니다.

이유:
1. 스레드 오버헤드: 각 스레드는 스택과 커널 리소스를 위한 메모리가 필요합니다.
2. 컨텍스트 스위칭: 많은 스레드가 있으면 CPU가 스레드 간 전환에 더 많은 시간을 소비합니다.
3. 캐시 지역성: 단일 스레드 이벤트 루프는 더 나은 캐시 성능을 가집니다.
4. 동기화: 단일 스레드 모델은 복잡한 동기화 필요성을 피합니다.
5. 확장성: 이벤트 기반 서버는 수만 개의 연결을 처리할 수 있지만, 클라이언트당 스레드 모델은 수천 개에서 리소스 제한에 도달합니다.

Nginx, Node.js, Redis와 같은 고성능 서버는 많은 동시 연결을 관리하기 위해 이벤트 기반 접근 방식을 사용합니다.[1]

**문제 3:** 스레드 T1이 동기화 없이 전역 변수 X를 수정하고, 스레드 T2도 동기화 없이 X를 읽습니다. 단일 CPU 시스템에서도 T2가 예상치 못한 값을 읽을 수 있는 상황은 언제인가요?

**해답:** T2가 예상치 못한 값을 읽을 수 있는 경우:

1. 변수 X가 단일 기계어 워드보다 크면(32비트 시스템에서 구조체나 long long과 같이): 다중 워드 변수 업데이트는 원자적이지 않습니다.
2. 컴파일러 최적화로 인해: 컴파일러는 메모리 읽기/쓰기를 재정렬하거나 변수를 레지스터에 캐싱할 수 있어 다른 스레드에게 보이지 않는 변경이 발생할 수 있습니다.
3. CPU가 메모리 접근을 재정렬할 수 있어 쓰기와 읽기가 다른 순서로 발생할 수 있습니다.
4. CPU 캐시 일관성 지연으로 인해: 한 코어의 쓰기가 다른 코어의 캐시에 즉시 반영되지 않을 수 있습니다.

즉, 단일 CPU 시스템에서도 스레드가 메모리 위치에 원자적이지 않은 접근을 하면 일관성 없는 값이 보일 수 있습니다.[1]

**문제 4:** 다중 스레드 프로세스는 비용이 많이 드는 데이터베이스 검색 루틴을 호출합니다. 단일 스레드 프로세스가 동일한 작업을 수행하는 것과 비교하여, 다중 스레드 접근 방식이 제공하는 주요 이점과 이 이점을 최대화하는 데 필요한 조건은 무엇인가요?

**해답:** 다중 스레드 접근 방식의 주요 이점은 하나의 스레드가 데이터베이스 검색으로 차단되어 있는 동안 다른 스레드가 계속 실행될 수 있다는 것입니다. 이는 전체 CPU 활용도와 응답성을 향상시킵니다.

이 이점을 최대화하기 위한 조건:
1. I/O와 CPU 작업의 균형: 데이터베이스 검색이 스레드를 차단하는 동안 다른 스레드는 유용한 계산 작업을 수행해야 합니다.
2. 효율적인 동기화: 스레드 간 동기화 오버헤드가 얻는 이점보다 작아야 합니다.
3. 독립적인 작업: 스레드가 서로에게 너무 자주 종속되지 않도록 작업을 독립적인 단위로 분할해야 합니다.
4. 적절한 스레드 수: 너무 많은 스레드는 컨텍스트 스위칭 오버헤드를 증가시킵니다. 최적의 스레드 수는 일반적으로 CPU 코어 수에 I/O 대기 시간을 CPU 작업 시간으로 나눈 비율을 곱한 값입니다.
5. CPU 개수: 물리적 CPU가 여러 개 있으면 진정한 병렬 처리가 가능해져 이점이 크게 향상됩니다.[1]

**문제 5:** 프로세스에는 4개의 스레드가 있으며, 모든 스레드는 같은 전역 변수에 접근합니다. 어떤 스레드도 뮤텍스를 사용하지 않습니다. 그러나 흥미롭게도 변수가 손상되지 않습니다. 이것이 가능한 이유를 설명하고, 이것이 충분한 동기화 전략인지 판단하세요.

**해답:** 이것이 가능한 이유:
1. 모든 접근이 읽기 전용일 수 있습니다(쓰기 없음).
2. 하나의 스레드만 값을 수정하고 다른 스레드는 읽기만 할 수 있습니다.
3. 변수 접근이 원자적일 수 있습니다(정수와 같은 단일 기계어 워드 크기).
4. 스레드가 사실상 순차적으로 실행되어 실제 병렬성이 없을 수 있습니다(예: 단일 코어).
5. 운이 좋아 경쟁 조건이 아직 발생하지 않았을 수 있습니다.

이것은 충분한 동기화 전략이 아닙니다. 이러한 접근 방식은 비결정적이고 다음과 같은 여러 문제에 취약합니다:
- 다른 하드웨어, 컴파일러 또는 OS에서 실패할 수 있습니다.
- 작업 부하가 변경되면 실패할 수 있습니다.
- 컴파일러 최적화가 메모리 접근 순서를 변경할 수 있습니다.
- 다중 코어 시스템에서는 거의 확실히 실패합니다.
- 예측할 수 없는 드문 버그를 일으킬 수 있습니다.

공유 데이터에 대한 적절한 접근 방식은 항상 뮤텍스, 원자적 작업 또는 다른 동기화 메커니즘을 사용하는 것입니다.[1][2]
